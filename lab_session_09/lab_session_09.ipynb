{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "rhy9pCfqnw0t",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "89920521958bef7e2fb28599ee920108",
     "grade": false,
     "grade_id": "cell-86ed8cbc1e5585ec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# CSE204 - Introduction to Machine Learning - Lab Session 9: Decision Trees and Ensemble Methods\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/adimajo/CSE204-2021/master/data/logo.jpg\" style=\"float: left; width: 15%\" />\n",
    "\n",
    "[CSE204-2021](https://moodle.polytechnique.fr/course/view.php?id=12838) Lab session #09\n",
    "\n",
    "J.B. Scoggins - Adrien Ehrhardt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "8ZG8kCLq9by1",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ceef4ae3c06784c5c2c480aa371197c1",
     "grade": false,
     "grade_id": "cell-28d1ca2967915c6e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this lab you will learn how to use decision trees and ensemble methods to build a model which predicts the average price of houses for neighborhoods in the US state of California. We will make heavy use of the following libraries, to which you are already familiar, to play with the dataset and build our models:\n",
    "\n",
    "- [Pandas](https://pandas.pydata.org/) - python data analysis library\n",
    "- [Scikit-learn](https://scikit-learn.org/stable/) - python machine learning library\n",
    "\n",
    "Recall from the lecture that decision trees can be a powerful way to generate \"cheap\" (because fast to build) and efficient models for classification and regression. Some of the advantages of decision trees over other models include:\n",
    "\n",
    "- They are easy to use, requiring little data preprocessing,\n",
    "- Can be easily interpreted,\n",
    "- Are useful for feature selection,\n",
    "- Fast to build and evaluate,\n",
    "- Non-linear.\n",
    "\n",
    "On the other hand, some of the disadvantages include:\n",
    "\n",
    "- Greedy tree building algorithms are not necessarily optimal (this is NP-complete),\n",
    "- The number of samples is logarithmic in tree depth,\n",
    "- Trees are unstable, meaning they can be easily perturbed (you would get a totally different tree) with small differences in data (e.g. subsamples),\n",
    "- Decision trees tend to overfit the data,\n",
    "- Since they only consider a single feature at a time, they have difficulty handling model additivity.\n",
    "\n",
    "Often, decision trees can be poor classifiers or regressors. However, because of their fast training speed, they can be used to generate ensemble models, such as random forests, with boosting and bagging.\n",
    "Often, the algorithm that is boosted or bagged is called the **weak learner**, meaning that they would be pretty lame on their own, but ensembling many weak learners can lead to a **strong learner**.\n",
    "We will play with some of these concepts during this lab in order to compare the resulting model to basic decision tree performance. Before we get started, let's import and load the different packages we will use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9959a890439f4d53e02baa0d724f4fd0",
     "grade": false,
     "grade_id": "cell-f8a2b83abb110d81",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Crash course on ensemble methods**\n",
    "\n",
    "Ensemble methods can roughly be divided into two categories: **bagging** and **boosting**.\n",
    "\n",
    "**Bagging**, or bootstrap aggregation, is a method which yields $B$ bootstrap samples, *i.e.* $B$ new training datasets of $(x_i^{(b)}, y_i^{(b)})_1^n$ with $1 \\leq b \\leq B$, where the $n$ samples are drawn **with replacement** from the original dataset $(x_i, y_i)_1^n$. A **weak learner** (e.g. a decision tree) is learned on each bootstrap sample, yielding a model $\\hat{f}^{(b)}$. For a new point $x$ for which we want to predict $y$, the estimate is given by:\n",
    "$$\\hat{f} = \\dfrac{1}{B} \\sum_{b=1}^B \\hat{f}^{(b)}(x).$$\n",
    "\n",
    "In the case of decision trees, recall that $\\hat{f}^{(b)}(x)$ is the mean (resp. the mode) of the leaf of the tree where the new point $x$ lands for regression (resp. classification). **Random Forests** are a generalization of **bagging** where the set of features $(X^j)_{j \\in S_b}$ available for each decision tree is sampled **without replacement** (obviously!) from the original set of features $(X^j)_1^d$ and generally with only a fraction of them (*i.e.* $|S_b| = k << d$). The combination of bootstraping the samples and drawing the features yields a robust prediction (much less variance than a single decision tree) and a better performance.\n",
    "\n",
    "**Boosting**\n",
    "\n",
    "Contrary to **bagging** which can be done in parallel (*i.e.* we fit $B$ independent model), in **boosting** we serialize models. A first model (*e.g.* a decision tree) is fit on the original dataset. Individual errors are computed, *i.e.* $E(y_i, \\hat{f}^{(0)}(x_i))$ and points in the training dataset are weighted according to this error (*i.e* we progressively concentrate on points for which we make the biggest error). Iterating this process, we get:\n",
    "$$\\hat{F}^{(0)}(x) = \\hat{f}^{(0)}(x),$$\n",
    "$$\\hat{F}^{(b)}(x) = \\hat{F}^{(b-1)}(x) + \\alpha_b \\hat{f}^{(b)}(x),$$\n",
    "\n",
    "for $1 \\leq b \\leq B$ where $\\alpha_b$ is a coefficient to determine and $\\hat{F}^{(B)}$ is our final predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "V16HlR0yGw_0",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d21967c6bcfa480971638ea97757acd5",
     "grade": false,
     "grade_id": "cell-a6a7d4b846039553",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from IPython.display import display\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz, plot_tree\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor\n",
    "\n",
    "import graphviz\n",
    "\n",
    "# Setup pandas options\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.1f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "KtZLwhEu9by7",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "acb2322f3d1966b263f84885add956cd",
     "grade": false,
     "grade_id": "cell-7ce2a339a2e6d589",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Data exploration with Pandas\n",
    "\n",
    "As we will be using the Pandas library, it is important you remember the core functionality from your previous labs.\n",
    "If you want a quick Pandas refresher, you can follow a simple Pandas tutorial provided by the [Google Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course/).\n",
    "\n",
    "This lab will partially resemble [lab_session_01](https://adimajo.github.io/CSE204-2021/lab_session_01/lab_session_01.html), insofar as we will explore a dataset, and adjust decision trees (as well as ensemble methods by the end of the lab)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "miBPxAKV9by8",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d91b5ff79f2bd8176ab941bc42231efc",
     "grade": false,
     "grade_id": "cell-80246dff0cb7c04c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 1: Get to know your dataset\n",
    "\n",
    "In this lab we will make use of the [California housing price dataset](https://developers.google.com/machine-learning/crash-course/california-housing-data-description) (this will be useful later on). This data was compiled from the 1990 census taken in California.  You can download the dataset with the Pandas code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "ef8J_Wjd9by9",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d20a881bb5aaedbd54fef089fd0a60a",
     "grade": false,
     "grade_id": "cell-b2b1b182d7c0e587",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Get the housing data\n",
    "housing_data = pd.read_csv(\n",
    "    \"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "2xF5HukS9bzB",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8f593b431df281cf34f7ee894e528ca2",
     "grade": false,
     "grade_id": "cell-6347572dd59f7a27",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As you are probably well aware at this point, one of the most important aspects of machine learning and data science is to first understand your dataset. Whenever you are introduced to a new dataset, it is crucial to learn everything you can about the data to help your model building strategy. The Pandas library is very useful for this purpose.\n",
    "\n",
    "**Exercise 1.1:** Using the describe() method to print information about the `housing_data` data frame and answer the following questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "NLnB_czl9bzD",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0b1ad7fde5d49546fafb7ce8ec754b4c",
     "grade": false,
     "grade_id": "cell-d714c328450a0e4c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5730fa3c26e8b323301d21b1d34cd9b1",
     "grade": false,
     "grade_id": "cell-98f3558baa9d60fc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "1. How many features are in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aafb78484b3d2dc23ff5cc584a4d8147",
     "grade": false,
     "grade_id": "cell-b9c596ec8b5866da",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# number_of_features = ...  # <- TO UNCOMMENT AND COMPLETE\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "385356eda284adbf878de24350cc7edf",
     "grade": true,
     "grade_id": "cell-0616135e6d03b496",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6be63cc7b319a4d45d830bf06f831023",
     "grade": false,
     "grade_id": "cell-a8d0ff72a942c281",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "2. How many samples are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f4449b78292d4172f99a0c71b519a919",
     "grade": false,
     "grade_id": "cell-92f189c6f5afb327",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# number_of_samples = ...  # <- TO UNCOMMENT AND COMPLETE\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5124a170c3549c399f47f92aae6b71cf",
     "grade": true,
     "grade_id": "cell-fcb9c34ecb530d44",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7414e05a84dd0babf798aa43aaf3206d",
     "grade": false,
     "grade_id": "cell-5288743a85ad2b68",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "3. Do mean and standard deviations make sense for what you expect each variable to be?\n",
    "  - Are the latitude and longitude values consistent with California? (don't be afraid to check with Google maps - use either Markdown or code cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "78ae6a1ede56415da09e296231fe0f13",
     "grade": true,
     "grade_id": "cell-3610ef4b7b3dc32a",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1c8058cb41c8e75d65459fd5cf8bbb94",
     "grade": false,
     "grade_id": "cell-740ad704493aadf1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9666f9a1b079f809bc67fc660e29b019",
     "grade": false,
     "grade_id": "cell-42c8ee916c7d9b07",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "  - What do you think the units of `total_rooms` and `total_bedrooms` are?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d8d89f7d732938f65e0c1bfa5787682b",
     "grade": true,
     "grade_id": "cell-cc164a2743661fda",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4794921ef1ac5df9a5010ab754d0afb0",
     "grade": false,
     "grade_id": "cell-caebfc5e0e9f4384",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "  - What about the `median_income`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "59676f1b343e30aa3f852ebeda70fe58",
     "grade": true,
     "grade_id": "cell-6af19801f8ff1b39",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1a184bd5e483a7cd076354e5b4cd77ef",
     "grade": false,
     "grade_id": "cell-ed08c820282b3e22",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "4. Which feature(s) are we likely to want to predict (using all the others)? Put its name (as a `str`) in `feature_to_predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "515162f68ba8cb100e34919fec4eb527",
     "grade": false,
     "grade_id": "cell-2722352794f3d780",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# feature_to_predict = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ca5a2e8e46d110cfd19b614bfe9afce",
     "grade": true,
     "grade_id": "cell-5920b14fef36f52b",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "541fb801db74b4ff0cfe5869d7a5556a",
     "grade": false,
     "grade_id": "cell-2bc290ee0a28e98d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "5. Can you detect if there are any outliers in the data based on the minimum and maximum values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e6de6550346ce5e5d74dacba7fe137a7",
     "grade": true,
     "grade_id": "cell-add92a8d638580d7",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "82f49cb74f10c8b701a4c74eafad49d4",
     "grade": false,
     "grade_id": "cell-7f816e7c9e1c161c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "jk_uB-Tl9bzG",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "331a6684c519abac272ada10a8aa09d9",
     "grade": false,
     "grade_id": "cell-9034247840914557",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Exercise 1.2** From the previous question, it seems logical to think that the `total_rooms` and `total_bedrooms` are for an entire block, not a single house.  Let's check this assumption by creating two new variables called `rooms_per_person` and `bedrooms_per_person`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "nLOJUhDI9bzH",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e2b48eccb6bb5c4c07e83803f9b7d6f6",
     "grade": false,
     "grade_id": "cell-61e0683f0aa534e3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# housing_data[\"rooms_per_person\"] = ...  # <- TO UNCOMMENT AND COMPLETE\n",
    "# housing_data[\"bedrooms_per_person\"] = ...  # <- TO UNCOMMENT AND COMPLETE\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6b03927a3c39aa814fea310f5fb5d4fa",
     "grade": true,
     "grade_id": "cell-bd181087ef585944",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "Cct4S8by9bzL",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "49b8aacd75eb508a24b0edbf9ccdfa2b",
     "grade": false,
     "grade_id": "cell-744ec0bf2d2cb3f7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Exercise 1.3:** Get a visual feel for the data by plotting the median house value (maybe with `plt.scatter`?) on a scatter plot versus longitude and latitude (use color for house value).  Compare with a map of california such as [this one](https://www.google.com/search?q=california+maps&client=firefox-b-d&tbm=isch&source=iu&ictx=1&fir=KnETshNcnsi1VM%253A%252CMK2MjhZw7xRERM%252C_&vet=1&usg=AI4_-kSz1S_ut8rli9wcyp0A12LG1aVofg&sa=X&ved=2ahUKEwju59vrxsDhAhXqyIUKHZAkBBgQ9QEwBXoECAgQDg#imgrc=KnETshNcnsi1VM:).  (Hint: normalize the median house value by the maximum.)\n",
    "\n",
    "- Does this make sense?\n",
    "- Where are the most expensive homes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "nXVJdl5O9bzM",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a557d0105e4607700d23b9942534a264",
     "grade": true,
     "grade_id": "cell-36d1ebb900c2aee0",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9c79b84e63927f73ca97e59255816d82",
     "grade": true,
     "grade_id": "cell-f2f4b6ddd8eaf7c7",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "3ykR6Bmm9bzQ",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "22adc6309c6a3335bb53b61219379f45",
     "grade": false,
     "grade_id": "cell-daebcc74f789a213",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Exercise 1.4:** Before building a model, let's build some expectation for what the important features are (just like we did for [lab_session_01](https://adimajo.github.io/CSE204-2021/lab_session_01/lab_session_01.html). This will help us interpret our decision trees later on. Use the `corr()` method from Pandas to build a correlation matrix.  Recall that a correlation matrix tells us how correlated any two features are. For very positive values (close to 1.0), there is a strong correlation betwee the two features. Likewise, for very negative values (close to -1.0), it means that the parameters are negatively correlated. When the values are close to 0, there is no correlation.\n",
    "\n",
    "Plot a visual representation of the correlation matrix using the `imshow()` method from matplotlib.\n",
    "\n",
    "List which features (or groups of features) are strongly correlated (positive or negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "aItoD9Wb9bzR",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9e0567c324a5a926f30606a0da1d9c4",
     "grade": true,
     "grade_id": "cell-a808c77126c000dc",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a57ddabdde0e4f6496ba97f703fd0fc5",
     "grade": true,
     "grade_id": "cell-7088f54c06b865b9",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c5492cef144eab09a8a2c46c5a927498",
     "grade": true,
     "grade_id": "cell-cb3176801e407e71",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "gw8MaLkt9bzV",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "97d1feade27a3fecb371c1c8f3e34f83",
     "grade": false,
     "grade_id": "cell-fa34693a34c99f6c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Exercise 1.5:** Use scatter plots to visualize each pair of correlated variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "WaazH5Yv9bzW",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c81dde827c7d1bba735950155d9a226",
     "grade": true,
     "grade_id": "cell-b5edf9ea0ca36149",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "fzR5_roR9bzc",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fdeae97158d43cdc96a737b4d7dfa4a2",
     "grade": false,
     "grade_id": "cell-6e2a8d868e420ed5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Exercise 1.6:** Notice anything strange about the scatter plot with `median_house_value`? What's going here?  Use a [histogram](https://pandas.pydata.org/docs/reference/api/pandas.Series.hist.html) to get an idea of the distribution of this feature. \n",
    "\n",
    "- What does the histogram tell us about the distribution?\n",
    "- What could this mean about how the data was collected or processed to build the database?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "id": "qzY2OlqgnkKQ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd62300af5b2c636c181a76022f53059",
     "grade": true,
     "grade_id": "cell-df9da49fd502a9ed",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "acbc5dd6ff6b6fa508053c2ee882b26e",
     "grade": true,
     "grade_id": "cell-a3b1c7361b2075e9",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "vY-rs_nK9bzg",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7c48ec8efb8c4eac1e1126c46e5a6ca7",
     "grade": false,
     "grade_id": "cell-06ca191a8f0570c8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 2: Train a simple decision tree to predict median house values\n",
    "\n",
    "At this point we have a pretty good idea about our dataset. Let's try and create a simple model based on a decision tree.\n",
    "\n",
    "**Exercise 2.1:** Implement the `custom_train_test_split` below to split the dataset into a training and validation set. Use the [`train_test_split()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function from Scikit-learn with `shuffle`, passed as an argument from `custom_train_test_split` set to `False`. Check that the reduced datasets make sense with the `describe()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "3MrsXBsg9bzi",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f49624b7e413b71f7647071b02b4b66a",
     "grade": false,
     "grade_id": "cell-dab3f4cc3baf5c2c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def custom_train_test_split(hs_data: pd.DataFrame = housing_data,\n",
    "                            feature_to_predict: str = feature_to_predict,\n",
    "                            test_size: float = 0.3,\n",
    "                            shuffle: bool = False):\n",
    "    \"\"\"\n",
    "    Wrapper around sklearn's train_test_split\n",
    "\n",
    "    :param pd.DataFrame hs_data: our dataset (default: housing_data)\n",
    "    :param str feature_to_predict: the feature to predict (default: feature_to_predict defined earlier)\n",
    "    :param float test_size: proportion of samples in the test data (default: 0.3)\n",
    "    :param bool shuffle: passed to sklearn => whether or not to shuffle the data or take the test_size first ones\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d06fca8a0c8063207942488d13cf5a47",
     "grade": true,
     "grade_id": "cell-185e558b40932e38",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "training_features, testing_features, training_target, testing_target = custom_train_test_split(shuffle=False)\n",
    "training_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49de54bbfc6e04becc694932c74a776f",
     "grade": true,
     "grade_id": "cell-3c8d410082b85bc3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "S9GEIN_k9bzl",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b9ed7056314f71f5a612f885af8c4d96",
     "grade": false,
     "grade_id": "cell-37573f1b370c92c0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Exercise 2.2:** As a second check, redo the scatter plot from Exercise 1.3 for both the training and testing subsets.  \n",
    "\n",
    "- Is this what you expected?  \n",
    "- What went wrong?\n",
    "\n",
    "Copy / paste your scatter plot from 1.3 below and run it on unshuffled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "x8BIZLjB9bzm",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "04a9ab1d39b7d93d3e36eb05001b4bfa",
     "grade": true,
     "grade_id": "cell-83f468eba4d75015",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Your plot on unshuffled data here\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7a583c7742f824b72463cf3900c692e2",
     "grade": false,
     "grade_id": "cell-208863dfd521893d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This is an important lesson.  In all of our dataset checking from Exercise 1, we didn't get a feel for the ordering of the data.  Ideally, we want our validation and training data to be identically distributed, however we did not take into account that the dataset has a clear ordering.  Normally, the `train_test_split()` defaults to shuffle our data for us to avoid such issues but we have turned this off expicitly.\n",
    "\n",
    "Call `custom_train_test_split` again with `shuffle=True` **and redo the scatter plot**. Have we been able to solve this problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "62c7247c9d3a5f90d4e216cb9a7edcf6",
     "grade": false,
     "grade_id": "cell-d0a05bc5a53b3e87",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "training_features, testing_features, training_target, testing_target = custom_train_test_split(shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba2334743651d1698ff4c9a8c1dba8cf",
     "grade": true,
     "grade_id": "cell-5862188150737d86",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Your plot here\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "aaOwZY5S9bzo",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5abaec94c4fcdb3bc56178ca72096ab3",
     "grade": false,
     "grade_id": "cell-33fa6c5630e3e32b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Exercise 2.3:** Use the `DecisionTreeRegressor` from Scikit-learn to create a new decision tree model with a depth of 3, the standard squared error, and train it on the training dataset using the `fit()` method.\n",
    "\n",
    "*Hint*: You can find the API for DecisionTreeRegressor [here](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "Nj9skxw-9bzp",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9bd6a062d16855a77fc795045c4e7af2",
     "grade": false,
     "grade_id": "cell-c5b2c389358bf4fd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# model = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6c35c6e157aaf1def0bd1341d98eb332",
     "grade": true,
     "grade_id": "cell-a5822d410b58ee17",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "WyEIFnm69bzq",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6b14aee15aeca1cf79c7fc26c12d28b5",
     "grade": false,
     "grade_id": "cell-69b92893696b98d0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Exercise 2.4:** Let's get a sense of how well the tree fits the data.\n",
    "\n",
    "* Use the tree's `predict` method on the testing features to get a prediction for the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "755a332c1592f10be69e749174ed0f96",
     "grade": false,
     "grade_id": "cell-555828a2fe4e54c6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# prediction = ...  # <- TO UNCOMMENT AND COMPLETE\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "30d1f88144b14acde29467f9ffbba245",
     "grade": false,
     "grade_id": "cell-369d6214b9cd8d00",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "* Compute the mean squared error using the `mean_squared_error()` function from Scikit-learn and assign it to `MSE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c8ca3f62735e70eb28ee74728773fde",
     "grade": false,
     "grade_id": "cell-6e534394e53d03a6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# MSE = ...  # <- TO UNCOMMENT AND COMPLETE\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "688d16b64ef42dc2a70309f9a4b1cd14",
     "grade": false,
     "grade_id": "cell-84f38ac78ce389f3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "* Plot a scatter plot of the predicted median house values versus the testing target values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "ENd-nNFM9bzs",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "30967ef7196664afaaa0303c89081db2",
     "grade": false,
     "grade_id": "cell-1421ed87112014fc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# plt...  # <- TO UNCOMMENT AND COMPLETE\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ba7871058b870bb97c25e421f258db0",
     "grade": true,
     "grade_id": "cell-2e34e84e34b697f2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b381670bd1aae0ff5430f944d394a849",
     "grade": false,
     "grade_id": "cell-8d239bbf7914094d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- Is the prediction good?\n",
    "- What does the scatter plot look like?\n",
    "- How many unique values are there in our predictions? Why is this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8b2b81bfa8c1e5e65ce74c20e7e974a6",
     "grade": true,
     "grade_id": "cell-f79baebbecddd77b",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "xxl2_P2I9bzu",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f93f721f49c94ec34ff01ba5938b50b8",
     "grade": false,
     "grade_id": "cell-d928b51d24b69b3a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Exercise 2.5** You can visualize the trained decision tree with the following code. As stated in the beginning, one advantage of such trees is that they are easily interpretible with graphs like this one. If you did not manage to install graphviz, the following cell will error. You may leave it as is and use the subsequent cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "kYs98IPp9bzv",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6492cc376cac8b58fc8a0e0f43356db8",
     "grade": false,
     "grade_id": "cell-9de5e4744bf65526",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Note, you may need to change 'model' to your tree's name\n",
    "dot_data = export_graphviz(\n",
    "    model, out_file=None, feature_names=list(training_features), filled=True, \n",
    "    rounded=True, special_characters=True)\n",
    "graph = graphviz.Source(dot_data) \n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(2, 2), dpi=600)\n",
    "plot_tree(model,\n",
    "          feature_names = list(training_features),\n",
    "          class_names=feature_to_predict,\n",
    "          filled = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dad58d560662da89f0f7b7897ed31d0c",
     "grade": false,
     "grade_id": "cell-be2f554d9076cd24",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- What are the main features used in the tree?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9a338d33486d293f0d3e5b5dd95e31a2",
     "grade": true,
     "grade_id": "cell-7def8c6f260f632d",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ec69de2a6c9a467a40e2c07f40eefbd9",
     "grade": false,
     "grade_id": "cell-d55bafbd10264ade",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- How do these compare to the features correlated to `median_house_value` you identified in Exercise 1.4?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "529d865f389dfa9eacf91c93ad458a41",
     "grade": true,
     "grade_id": "cell-c1674b9955b98b4d",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "GCyx0VRE9bzw",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "56a63d4780d9b274824afc0ed4e68cb3",
     "grade": false,
     "grade_id": "cell-5908d0f44a87b2aa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Exercise 2.6** Repeat 2.3 and 2.4 **below* *for different values of the maximum tree-depth*.\n",
    "\n",
    "- How does the fit improve with increasing depth?\n",
    "\n",
    "Note that you can try visualizing the tree with larger depth values, but it becomes difficult as the tree grows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cbc307b614694838a686016dbe0a6b77",
     "grade": true,
     "grade_id": "cell-45251d418261da5b",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "34203baf3ee40a52a7e0c398f37c4a03",
     "grade": true,
     "grade_id": "cell-bbb86fc3ee462548",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "WllPBU6B9bzx",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "97671a0c28009c10e98eec6bdb91bafe",
     "grade": false,
     "grade_id": "cell-2f6b64ba199d2b26",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 3: Ensemble methods\n",
    "\n",
    "We have seen that a single decision tree is not a very good estimator.  We can improve our predictions using a number of ensemble techniques such as bagging, random forests, and boosting.  Using Scikit-learn, it is easy to try all of these models.  Here are the main classes that we will test:\n",
    "\n",
    "- [BaggingRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html#sklearn.ensemble.BaggingRegressor)\n",
    "- [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)\n",
    "- [ExtraTreesRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html)\n",
    "- [AdaBoostRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html)\n",
    "\n",
    "Follow each link to read about the details of each method. In the following exercises you will train each type of regressor using a max_depth of 10 layers and test their prediction accuracy. Finally, you can perform a hyperparameter study to try and find the optimal model/parameter pair which minimizes the MSE on the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10d2ef48cfe0abb99ea8b9149e605f46",
     "grade": false,
     "grade_id": "cell-573a0ed07ba8106d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def fit_and_get_test_error(model,\n",
    "                           training_features: np.array = training_features,\n",
    "                           training_target: np.array = training_target,\n",
    "                           testing_features: np.array = testing_features,\n",
    "                           task: str = \"regression\"):\n",
    "    model.fit(training_features, training_target)\n",
    "    prediction = model.predict(testing_features)\n",
    "    if task == \"regression\":\n",
    "        return mean_squared_error(prediction, testing_target)\n",
    "    else:\n",
    "        return accuracy_score(testing_target, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "B8puJOxH9bzy",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b0ef1d8fbe017fde8ee60d1a7907ce33",
     "grade": false,
     "grade_id": "cell-30ffc3f1f4c72bcd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Exercise 3.1:** Create and fit a bagging regressor based on decision trees with a max depth of 10 using 100 trees, and maximum samples and features of 50%.  Compute the MSE on the testing dataset and compare the true median house values with the predictions using a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "kCoU1eHv9bzz",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9d7024c41af3f671f81277f5bb39e134",
     "grade": false,
     "grade_id": "cell-4b13e0ce66664808",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# model = ...  # <- TO UNCOMMENT AND COMPLETE\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "bagging_prediction = fit_and_get_test_error(model)\n",
    "print(bagging_prediction)\n",
    "plt.scatter(testing_target, model.predict(testing_features));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b44e5ab02f062e739474244edb75e16",
     "grade": true,
     "grade_id": "cell-23872406e7a0396e",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "TvzZDoK29bz2",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cc3c12efd51aacf165a2d52aa7c2c689",
     "grade": false,
     "grade_id": "cell-adf8a5dd76f4473c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Exercise 3.2:** Create and fit a random forest regressor with a max depth of 10.  Compute the MSE on the testing dataset and compare the true median house values with the predictions using a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "1WkEhRE79bz2",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d1eed7e67083b0b501f950b3339edc2e",
     "grade": false,
     "grade_id": "cell-1867aca2acd36b47",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# model = ...  # <- TO UNCOMMENT AND COMPLETE\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "rf_prediction = fit_and_get_test_error(model)\n",
    "print(rf_prediction)\n",
    "plt.scatter(testing_target, model.predict(testing_features));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd240888f81c8142eada02819d9567a5",
     "grade": true,
     "grade_id": "cell-5d554d584a1b0a77",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "6LRNQvxP9bz4",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1c125ba337fd5471617c3976308a82c0",
     "grade": false,
     "grade_id": "cell-d2074c01620f8f99",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Exercise 3.3:** Create and fit an extremely randomized trees regressor (ExtraTreesRegressor) with a max depth of 10.  Compute the MSE on the testing dataset and compare the true median house values with the predictions using a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "JvRCKFjo9bz5",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "48b8ba1cd4a8b1d8f3404e88f2b4f7fb",
     "grade": false,
     "grade_id": "cell-8858b4805a0de6ad",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# model = ...  # <- TO UNCOMMENT AND COMPLETE\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "xtra_prediction = fit_and_get_test_error(model)\n",
    "print(xtra_prediction)\n",
    "plt.scatter(testing_target, model.predict(testing_features));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "16f007b774d1af59c4022f1f281137e0",
     "grade": true,
     "grade_id": "cell-c53895a5aa3ae67f",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "PRjMfVoi9bz_",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1169823357dd904e1f5fa0ec89bfff59",
     "grade": false,
     "grade_id": "cell-40e18157f25d006c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Exercise 3.4:** Create and fit a tree ensemble regressor with boosting (AdaBoostRegressor) with a max depth of 10.  Compute the MSE on the testing dataset and compare the true median house values with the predictions using a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "4RU2MD-89b0A",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "87295d157f4292e92ff2bf423efe4b15",
     "grade": false,
     "grade_id": "cell-90566a05bde9007a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# model = ...  # <- TO UNCOMMENT AND COMPLETE\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "ada_prediction = fit_and_get_test_error(model)\n",
    "print(ada_prediction)\n",
    "plt.scatter(testing_target, model.predict(testing_features));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ee9538dc132a86cf5b3f7cdcca4a2a3e",
     "grade": true,
     "grade_id": "cell-303b7d10d7b97c4e",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "8PnmD7b89b0E",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6438c31e457327d5bd8298984eb9e9ed",
     "grade": false,
     "grade_id": "cell-ec096f5f98d423dc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Exercise 3.5:** Plot the MSE for each of the four ensemble methods above versus the maximum depth used (from 2 to 20).\n",
    "\n",
    "- At what maximum depth do the different methods more or less converge?\n",
    "- Which is the best method in terms of minimum MSE obtained?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "oucz3-sd9b0F",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1855feb8bdbfc5583346a81ecccceba1",
     "grade": false,
     "grade_id": "cell-fcddae0275613d2f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Generate MSE data\n",
    "min_depth = 2\n",
    "max_depth = 20\n",
    "estimators = 100\n",
    "mse = np.zeros((max_depth-min_depth+1, 4))\n",
    "\n",
    "for i, D in enumerate(range(2,max_depth+1)):\n",
    "    # model = ...  # <- TO UNCOMMENT AND COMPLETE\n",
    "    # mse[i, ...] = test_error(model)  # <- TO UNCOMMENT AND COMPLETE\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "UtvHUYiZ9b0H",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f4bca1846fe9818f2ceac86937fb18b9",
     "grade": false,
     "grade_id": "cell-fffe639f823ad16a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Plot MSE curves for each model on a single plot\n",
    "for m in range(4):\n",
    "    plt.plot(range(min_depth, max_depth + 1), mse[:,m])\n",
    "plt.legend(['Bagging', 'Random Forest', 'Extremely Random Tree', 'Boosted'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8f259f98a9eb2c503ec62c1bcafab1a6",
     "grade": true,
     "grade_id": "cell-681cd2d90b4bfbcb",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "MUb-qv2i9b0K",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "492f12811cb84eb3cb5b8d1fc510d9c7",
     "grade": false,
     "grade_id": "cell-a7c0b3d57a6077c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Conclusions\n",
    "\n",
    "That's it for this lab!  Note there are still several ways you can try and improve the regression.  It might even be worth trying to use an entirely different model such as a neural network to see if you can obtain better performance.  Over time, you will build up an intuition for which models might work best on different datasets.  \n",
    "\n",
    "If you want more practice with trees and ensemble methods, checkout the Iris dataset below which is a classification problem.  You can use everything you learned here by replacing \"Regressor\" with \"Classifier\" as a Bonus below.  Happy coding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3460a36d02c1874148940da0f141e828",
     "grade": false,
     "grade_id": "cell-f84819c75b25b281",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "te2SI3mG9b0L",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f464a65a6550c4b000cc552f3c41dddf",
     "grade": false,
     "grade_id": "cell-aea6eb5cf5c30637",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "covertype = datasets.fetch_covtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(covertype.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "35ad7c9cb77522a8a8fd2702754c673a",
     "grade": false,
     "grade_id": "cell-5b126f2bc542f9fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "covertype_df = pd.DataFrame(covertype.data)\n",
    "covertype_df['cover'] = covertype.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fee0666b8568565e92ba2c7091a4d464",
     "grade": false,
     "grade_id": "cell-232cd2db6de87a96",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "training_features, testing_features, training_target, testing_target = custom_train_test_split(\n",
    "    hs_data=covertype_df,\n",
    "    feature_to_predict='cover',\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "42de678b4155229177c28ca83233932d",
     "grade": true,
     "grade_id": "cell-33a9044f22512147",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copie de Untitled0.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/jbscoggi/teaching/blob/master/Polytechnique/CSE204/Lab9.ipynb",
     "timestamp": 1576227393089
    }
   ]
  },
  "kernelspec": {
   "display_name": "CSE204",
   "language": "python",
   "name": "cse204"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
