{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8d2bdd687513555d66e7c5facf3e4f56",
     "grade": false,
     "grade_id": "cell-b39ba8df0326a24a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "meta",
     "toc_en"
    ],
    "toc-hr-collapsed": false
   },
   "source": [
    "# CSE204 - Introduction to Machine Learning - Lab Session 4: regression methods\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/adimajo/CSE204-2021/master/data/logo.jpg\" style=\"float: left; width: 15%\" />\n",
    "\n",
    "[CSE204-2021](https://moodle.polytechnique.fr/course/view.php?id=10682) Lab session #04\n",
    "\n",
    "Jérémie DECOCK - Adrien EHRHARDT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5bffc4ce96e1c9c3b083522840e45cde",
     "grade": false,
     "grade_id": "cell-d0875250000514a2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7200f2df957dd49fcc545910e6872610",
     "grade": false,
     "grade_id": "cell-4660f8a8543f4de6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the lab session 02, we have used a **parametric model** to solve **regression problems**. In lab session 03, we used k-NN, a **non-parametric model** on (mostly) classification **and** regression problems, as well as logistic regression, a **parametric model** on classification tasks.\n",
    "\n",
    "Today you will continue the exploration of regression methods (both parametric and non-parametric), and of logistic regression. On today's agenda:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8950fa77fa2dc0630d11c735f7bada0d",
     "grade": false,
     "grade_id": "cell-8c37e2cf4c31fd2e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- Pathological Cases: ordinary least squares gone wrong\n",
    "- Regularization with linear and logistic regression\n",
    "- Weighted Least Squares\n",
    "- Kernel Regression: \"local\" dependence, like k-NN\n",
    "- Local Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2b61c9c0bb7ed37625f7a559cff65538",
     "grade": false,
     "grade_id": "cell-c34a085df16ca768",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Note**: as in the previous labs, there are some differences in notations with the lecture slides. For instance, parameters are noted $w$ (machine learning community) in lectures but they are noted $\\theta$ here (statistics community)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0fe3b04f642fd9345ccaab7c1597fa9a",
     "grade": false,
     "grade_id": "cell-d67210d0da4c39f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Imports and tool functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6aa1024fecbcee43697193b0381ba62b",
     "grade": false,
     "grade_id": "cell-9584dc80a176bfc6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "26623b85dc5a23acf7a3994d20eb994e",
     "grade": false,
     "grade_id": "cell-047253420253af9e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gen_2d_classification_samples(n_samples: int = 20, nclass: int = 3) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates 2-dimensional samples which belong to either 2 or 3 classes\n",
    "\n",
    "    :param int n_samples: number of samples to draw per class\n",
    "    :param int nclass: number of classes the samples belong to (either 2 or 3)\n",
    "    :returns: dataframe containing X (2 coordinates x1, x2) and y (as int!)\n",
    "    \"\"\"\n",
    "    cov = np.diag([2., 2.])\n",
    "\n",
    "    x1 = np.random.multivariate_normal(mean=[0., 0.], cov=cov, size=n_samples)\n",
    "    y1 = np.full(n_samples, 1, dtype=int)\n",
    "\n",
    "    x2 = np.random.multivariate_normal(mean=[4., 0.], cov=cov, size=n_samples)\n",
    "    y2 = np.full(n_samples, 2, dtype=int)\n",
    "\n",
    "    x3 = np.random.multivariate_normal(mean=[2., 4.], cov=cov, size=n_samples)\n",
    "    y3 = np.full(n_samples, 3, dtype=int)\n",
    "\n",
    "    if nclass == 3:\n",
    "        X = np.concatenate([x1, x2, x3])\n",
    "        y = np.concatenate([y1, y2, y3])\n",
    "    elif nclass == 2:\n",
    "        X = np.concatenate([x1, x2])\n",
    "        y = np.concatenate([y1, y2])\n",
    "    else:\n",
    "        raise ValueError(\"Only 2 or 3 classes\")\n",
    "\n",
    "    df = pd.DataFrame(X, columns=['x1', 'x2'])\n",
    "    df['y'] = y\n",
    "\n",
    "    df = shuffle(df).reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b6f2a01d7275c00a9a696c2a7af43f8",
     "grade": false,
     "grade_id": "cell-3a63a960d5a8b724",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gen_1d_polynomial_regression_samples(n_samples: int = 15) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate 1-dimensional regression samples (x, y)\n",
    "\n",
    "    :param int n_samples: how many samples to return\n",
    "    \"\"\"\n",
    "    x = np.random.uniform(low=0., high=1.5, size=n_samples)\n",
    "    y = np.cos(2. * np.pi * x) + np.random.normal(scale=0.1, size=x.shape)\n",
    "    df = pd.DataFrame(np.array([x, y]).T, columns=['x', 'y'])\n",
    "    df = sklearn.utils.shuffle(df).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb87c00be10f9a55247d0f6da4522dc8",
     "grade": false,
     "grade_id": "cell-d8cac13da15a6d08",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_1d_regression_samples(dataframe: pd.DataFrame, model=None):\n",
    "    \"\"\"\n",
    "    Plot the data in dataframe, as wellas (optionnally) the predictions from a model\n",
    "\n",
    "    :param pandas.DataFrame dataframe: dataframe containing 'x' and 'y'\n",
    "    :param model: model to predict\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    \n",
    "    df = dataframe.copy()  # make an alias\n",
    "    \n",
    "    ERROR_MSG1 = \"The `dataframe` parameter should be a Pandas DataFrame having the following columns: ['x', 'y']\"\n",
    "    assert df.columns.values.tolist() == ['x', 'y'], ERROR_MSG1\n",
    "    \n",
    "    if model is not None:\n",
    "        \n",
    "        # Compute the model's prediction\n",
    "        x_pred = np.linspace(df.x.min(), df.x.max(), 100).reshape(-1, 1)\n",
    "        y_pred = model.predict(x_pred)\n",
    "        df_pred = pd.DataFrame(np.array([x_pred.flatten(), y_pred.flatten()]).T, columns=['x', 'y'])\n",
    "        df_pred.plot(x='x', y='y', style='r--', ax=ax)\n",
    "\n",
    "    # Plot also the training points\n",
    "    df.plot.scatter(x='x', y='y', ax=ax)\n",
    "    delta_y = df.y.max() - df.y.min()\n",
    "    plt.ylim((df.y.min() - 0.15 * delta_y,\n",
    "              df.y.max() + 0.15 * delta_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "785a6f0dd0feb81b5fe2bb2e52465c42",
     "grade": false,
     "grade_id": "cell-58f4b97740e11f2b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_regression_1d(X, y, theta=None, x_min=0, x_max=2):\n",
    "    \"\"\"\n",
    "    Plot linear regression of X on y given theta\n",
    "    \"\"\"\n",
    "    assert X.ndim == 2 and X.shape[1] == 2, X.shape\n",
    "    assert y.ndim == 2 and y.shape[1] == 1, y.shape\n",
    "    if theta is not None:\n",
    "        assert theta.ndim == 2 and theta.shape == (2, 1), theta.shape\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(X[:,1], y)\n",
    "\n",
    "    if theta is not None:\n",
    "        x = np.linspace(x_min, x_max, 50)\n",
    "        y = theta[0] + theta[1] * x\n",
    "\n",
    "        ax.plot(x, y, \"--r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "203be3e841bcd44e8fd3294dce8d7467",
     "grade": false,
     "grade_id": "cell-ab3ce7cb987cf9a1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "toc-hr-collapsed": false
   },
   "source": [
    "## Pathological cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "310293472d2d950adbf17b114b47cf8f",
     "grade": false,
     "grade_id": "cell-d56983b241081b03",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Consider the following implementation of the least squares method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "827de24af1822fbb173ea84af88db56a",
     "grade": false,
     "grade_id": "cell-331fddcc2bbdd524",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def least_squares(X: np.array, y: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Perform linear regression via least squares, return coefficient\n",
    "\n",
    "    :param numpy.array X: design matrix (n-sample as rows, p features as columns)\n",
    "    :param numpy.array y: response vector (p elements)\n",
    "    :return: linear regression coefficient found via ols\n",
    "    :rtype: numpy.array\n",
    "    \"\"\"\n",
    "    XX = np.dot(X.T, X)\n",
    "    Xy = np.dot(X.T, y)\n",
    "    invXX = np.linalg.inv(XX)\n",
    "    theta = np.dot(invXX, Xy)\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "baa368a91a89f0a4c432010a84ac1e7c",
     "grade": false,
     "grade_id": "cell-8adff8da14d09559",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We want to use it to apply linear regression to some datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6e8680c2963ccd6ac97d2e4eadc930f9",
     "grade": false,
     "grade_id": "cell-3ab0290d3f338e31",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ec4867fef55c2c7994f59027e1a6e378",
     "grade": false,
     "grade_id": "cell-1c5d457eb642cd18",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8cb0d514fc695ff7e4d5485644f8a8c3",
     "grade": false,
     "grade_id": "cell-00ae87310db8e17c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "What is wrong with the following dataset ? (Try running both cells below, and give your answer in the third one.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aea15cfe92cf8c9019f547052dcfa0ac",
     "grade": false,
     "grade_id": "cell-e81d7c8d2d165e51",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X = np.array([[1, 3, 0],\n",
    "              [2, 3, 4]])\n",
    "y = np.array([1.8, 2.7])\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theta = least_squares(X, y)   # <- **TODO: UNCOMMENT**\n",
    "# theta                         # <- **TODO: UNCOMMENT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2b17da71e35e6ad4bd900082b0a5f924",
     "grade": true,
     "grade_id": "cell-769d24f9d9d63962",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a1b25f78c5d5d08230f284e08b4655b0",
     "grade": false,
     "grade_id": "cell-37a66d074d9f50a1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6d39165951d80dd8d5d383272d657181",
     "grade": false,
     "grade_id": "cell-3bcba46473e7f404",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "What is wrong with the following dataset ? (Try running both cells below, and give your answer in the third one.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8de92d91e120107a7ade06c763d480b2",
     "grade": false,
     "grade_id": "cell-5a00ad6861282ee9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X = np.array([[1, 2, 3, 4, 5], [2, 4, 6, 8, 10]]).T\n",
    "y = np.array([1.8, 2.7, 3.4, 3.8, 3.9])\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theta = least_squares(X, y)   # <- **TODO: UNCOMMENT**\n",
    "# theta                         # <- **TODO: UNCOMMENT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "51a146db7fb33df040cb44fc7c6fef41",
     "grade": true,
     "grade_id": "cell-25146a5104ebdce1",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "63e8111cdf1ff57717c623cfcb4d82a7",
     "grade": false,
     "grade_id": "cell-b477da0db92e150c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "toc-hr-collapsed": false
   },
   "source": [
    "## Regularization with Ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "22310eb6393abf6be69556aac8655fc1",
     "grade": false,
     "grade_id": "cell-7f28009ea2cffb80",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We have the following dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2cff44919e6fa53df50d606e9400cde9",
     "grade": false,
     "grade_id": "cell-683810b3cf23cb63",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "x = np.array([1, 2.5, 3, 4.2, 5.5])\n",
    "y = np.array([3.1, 3.5, 6.8, 10.9, 12.3])\n",
    "\n",
    "plt.scatter(x, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3a38b95066dd167929c305d6b381da10",
     "grade": false,
     "grade_id": "cell-daa454d9a6394dd4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We apply basis expansion to fit a polynomial model to the data (similar to lab_session_02)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd625b1c436085d8ef66d92997e38f88",
     "grade": false,
     "grade_id": "cell-200dd97ed95a5091",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def basis_expansion(x: np.array, degree: int = 4) -> np.array:\n",
    "    \"\"\"\n",
    "    Basis expansion (1, x, ..., x^degree)\n",
    "\n",
    "    :param numpy.array x: vector to be expanded\n",
    "    :param int degree: degree up to which (included) to perform the expansion\n",
    "    \"\"\"\n",
    "    # Intercept\n",
    "    Z_list = [np.ones(shape=x.shape)]\n",
    "    \n",
    "    # x^1, x^2, ..., x^degree\n",
    "    for deg_index in range(1, degree + 1):\n",
    "        Z_list.append(x**deg_index)\n",
    "    \n",
    "    return np.array(Z_list).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f4be13162f1085f66a1d34f66d44552",
     "grade": false,
     "grade_id": "cell-8cb63e9ea8f4c17d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "Z = basis_expansion(x)\n",
    "\n",
    "# Instanciate and fit the model\n",
    "model = sklearn.linear_model.LinearRegression(fit_intercept=False)\n",
    "model.fit(Z, y)\n",
    "\n",
    "print(\"Coefs:\", model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01afc10576d33a2b093536ea51e15245",
     "grade": false,
     "grade_id": "cell-2dc1d89f06f2369e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_regression(x: np.array, model=None, theta=None, degree: int = 4):\n",
    "    # Compute the model's prediction\n",
    "    x_pred = np.linspace(x.min(), x.max(), 100)\n",
    "    Z_pred = basis_expansion(x_pred, degree=degree)\n",
    "    if model is not None:\n",
    "        y_pred = model.predict(Z_pred)\n",
    "    elif theta is not None:\n",
    "        y_pred = np.dot(Z_pred, theta)\n",
    "    else:\n",
    "        raise ValueError('Provide either model or theta')\n",
    "\n",
    "    # Plot prediction and training set\n",
    "    fig, ax = plt.subplots(figsize=(18, 8))\n",
    "    ax.plot(x_pred, y_pred)\n",
    "    ax.scatter(x, y)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1d9515e264e2aff66eda63b2155423b1",
     "grade": false,
     "grade_id": "cell-6e41bfbf64550532",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plot_regression(x, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "03a3d070b8e242364f5e6c03642c960f",
     "grade": false,
     "grade_id": "cell-f3992f715734fd38",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As you can see, a polynomial function of degree 4 is certainly not adapted to fit efficiently these data. Here we have a clear over-fitting: the model is too complex for the data and it will have poor generalization performance (i.e. big error on new unknown data).\n",
    "In fact, since we only have 5 data points, any polynomial regression with degree >=4 would have more than 5 coefficients (when accounting for the intercept term) and would thus fit perfectly (i.e. go through) our 5 points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0185975ed6993fe8cf6179fc4404f648",
     "grade": false,
     "grade_id": "cell-ec20d899578239b9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "A solution is to reduce the complexity of the model using a lower polynomial degree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "897d49f4550bf6720333773787c5dcf9",
     "grade": false,
     "grade_id": "cell-a97b176f4a5514a5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "An alternative is to apply a *regularization method* like the *ridge regularization* (a.k.a. *L2 regularization*) which applies a penalty on the value of $\\theta$ to constrain it to be as small as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "730ebc66f7b915d7336411cd10e666af",
     "grade": false,
     "grade_id": "cell-1c955b310ae528d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "A $\\boldsymbol{\\theta}$ with small elements usually makes the model simpler and brings better generalization performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "58f7fe40328ce41c96bc3dd9da9f5e31",
     "grade": false,
     "grade_id": "cell-dd85ecdb148d9e75",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This L2 regularization is included in the least square method as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e4594b9209847c79d47843197899baac",
     "grade": false,
     "grade_id": "cell-76c4f837b465db4c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "$$\n",
    "\\boldsymbol{\\theta}^*\n",
    "\\leftarrow \\arg\\min_{\\boldsymbol{\\theta}} E(\\boldsymbol{\\theta})\n",
    "\\quad \\text{with} \\quad\n",
    "E(\\boldsymbol{\\theta})\n",
    "= \\underbrace{||\\boldsymbol{y} - \\boldsymbol{X} \\boldsymbol{\\theta}||^2_2}_{\\text{error term}} ~~ + \\underbrace{\\lambda ||\\boldsymbol{\\theta}||^2_2}_{\\text{regularization}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "882a6b1f83d42fdee36db5cc1cc98ac0",
     "grade": false,
     "grade_id": "cell-c6c6debf5100b610",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "where $\\lambda \\in \\mathbb{R}^+$ is the *regularization strength* coefficient:\n",
    "- when $\\lambda$ goes to infinity, the regularization term dominates the error term (MSE) and the coefficients $\\boldsymbol{\\theta}$ tend to zero;\n",
    "- when $\\lambda$ goes to 0, the regularization term looses the importance and eventually the regularization term is ignored;\n",
    "- $\\lambda$ is a *meta* or *hyper parameter*;\n",
    "- the best $\\lambda$ for a problem can be computed empirically or automatically\n",
    "- we're not interested in the best $\\lambda$ *per se* but in the best prediction performance on a test set, *i.e.* achieving a good bias-variance tradeoff. This is made easy by having a single parameter, $\\lambda$, to control this tradeoff, and calculating the desired criterion, e.g. MSE on a test set, for many values of $\\lambda$ (e.g. grid search);\n",
    "- to find this \"best\" lambda (i.e. corresponding to the best MSE on a test set), we usually plot the training and testing errors w.r.t. to lambda, and more generally, w.r.t. model complexity. This will be part of subsequent labs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5335ec20a9ad67669237042352bb51c8",
     "grade": false,
     "grade_id": "cell-9b23700bb1e62802",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4d0ecbbcf3c785f86d5745037a956854",
     "grade": false,
     "grade_id": "cell-aa344a3601d29c8b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "00cec2e5f113a1690cd660e4d47dd7bd",
     "grade": false,
     "grade_id": "cell-af103435b049e13f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "On a sheet of paper:\n",
    "- Compute the analytic formulation of the gradient $\\nabla_{\\boldsymbol{\\theta}} E(\\boldsymbol{\\theta})$\n",
    "- Compute the analytic formulation of the optimal parameter $\\boldsymbol{\\theta^*}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eadb5681e6ecae002b0333453ffae87d",
     "grade": true,
     "grade_id": "cell-d0e38e92f00050b9",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c86240436935a95be8b6bb34ade47892",
     "grade": false,
     "grade_id": "cell-3e5e013678e3dcad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ef785a8ef9994c820f6a4e7b5c0cae30",
     "grade": false,
     "grade_id": "cell-ce81f172c59bfed2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Is it a convex optimization problem like *Ordinary Least Squares* ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cade85901a9337883ae919fe976ba925",
     "grade": true,
     "grade_id": "cell-e55214b8bf672815",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "122e9ea8aea902698afdad5693f83ed6",
     "grade": false,
     "grade_id": "cell-7eb647111935ba84",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a09e7736ed074c413ad841e71df6b811",
     "grade": false,
     "grade_id": "cell-6e62cf87e0f1a320",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Check the following Scikit Learn implementation of the Ridge Regression (more info here: https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn.linear_model.Ridge(alpha=0, fit_intercept=False)\n",
    "model.fit(Z, y)\n",
    "coefs = [model.intercept_] + model.coef_\n",
    "print(\"Coefs:\", coefs)\n",
    "\n",
    "plot_regression(x, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a310ebedd326ad7a37601991e8d37fd8",
     "grade": false,
     "grade_id": "cell-2a8beaa017ab511c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Change the value of the `alpha` parameter in `sklearn.linear_model.Ridge` and explain what happens (in Scikit Learn the $\\lambda$ regression strength is named $\\alpha$, and sometimes its inverse is referred to as $C$, e.g., in `LogisticRegression`, see previous lab)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fe74dc66c07f30f656d989376cd98193",
     "grade": true,
     "grade_id": "cell-194dcb30830e3b76",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e60bb21f4944f1f38ccac55ff604552b",
     "grade": false,
     "grade_id": "cell-34d41e843476c0c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0e2798c47894c27b7990728e06d73cda",
     "grade": false,
     "grade_id": "cell-e3cd91daee05a3e6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Plot Ridge coefficients as a function of the regularization parameter.\n",
    "\n",
    "Evaluate the following sequence of regularization strength: `alphas = np.logspace(-2, 5, 50)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "724b2f7533b155f565fad83fa1c18f60",
     "grade": false,
     "grade_id": "cell-192bb9689974cff6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Compute paths\n",
    "alphas = np.logspace(-2, 5, 50)\n",
    "\n",
    "coefs = []\n",
    "for a in alphas:\n",
    "    # Fit a `Ridge` object\n",
    "    # coefs.append(...)  # TO UNCOMMENT: append the ridge coefficients to the `coefs` list\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "18780d16b7bc34dfe99b23a1034abb55",
     "grade": true,
     "grade_id": "cell-db41f1411f0260ee",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Display results\n",
    "fig, ax = plt.subplots(figsize=(18, 8))\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')\n",
    "plt.title('Ridge coefficients as a function of the regularization')\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d568c3aca9b945b3f3f32beca053bab0",
     "grade": false,
     "grade_id": "cell-22bc876e172f955a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b392fb62cec057b55aa4d9e68b799475",
     "grade": false,
     "grade_id": "cell-acdb44b8be0f5f90",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Update the following function to implement the ridge regression in Python (without using Scikit Learn). Check it as in question 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "99912ec47c111de4b7570b9d9ce5367e",
     "grade": false,
     "grade_id": "cell-a3e4435c9b2baaa4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ridge_regression(X, y, lambda_):\n",
    "    XX = np.dot(X.T, X)\n",
    "    Xy = np.dot(X.T, y)\n",
    "    # invXX = ...\n",
    "    # theta = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80509b59736ffa25a7c9e203748bbe38",
     "grade": true,
     "grade_id": "cell-6c21d1c6b41ee2b5",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "theta = ridge_regression(Z, y, lambda_=6.)\n",
    "\n",
    "print(\"Coefs:\", theta)\n",
    "\n",
    "plot_regression(x, theta=theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "52ad0f59f01a6931a3bf26773421c669",
     "grade": false,
     "grade_id": "cell-294e695f17e8ebc3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Ridge Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f0ec84c051487335307be26d846af900",
     "grade": false,
     "grade_id": "cell-3019cc6c5598af32",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "95defd9432e8dddba62623ac06c9a0e9",
     "grade": false,
     "grade_id": "cell-4b7455d8a6881c65",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's use our 2D classification example from lab_session_03."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0591cbf8baf907bf01a1a0e87b97d079",
     "grade": false,
     "grade_id": "cell-927f4a53c59bde7d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = gen_2d_classification_samples(n_samples=50, nclass=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "862b785f521e6c095fb7046e8165b5f9",
     "grade": false,
     "grade_id": "cell-527c211896a03562",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "x_min, x_max = np.array((df.x1, df.x2))[0, :].min() - .5, np.array((df.x1, df.x2))[0, :].max() + .5\n",
    "y_min, y_max = np.array((df.x1, df.x2))[1, :].min() - .5, np.array((df.x1, df.x2))[1, :].max() + .5\n",
    "h = .02  # step size in the mesh\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "plt.scatter(df.x1, df.x2, c=df.y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d21fdb4c6dca1a30b2c65f5c07f0c19b",
     "grade": false,
     "grade_id": "cell-c1f8e06719bc7c7d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We used gradient descent to fit a Logistic Regression and draw a linear decision boundary between these two classes.\n",
    "\n",
    "Recall the `LogisticRegression` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f3c596a8eefba658850e93e8c4dd5020",
     "grade": false,
     "grade_id": "cell-f55bc257ae956696",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "logistic_regression = sklearn.linear_model.LogisticRegression(C = 1e9).fit(\n",
    "    df[['x1', 'x2']].values,\n",
    "    df.y.values - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a9aa187b613ebd581bae2df308a3abe",
     "grade": false,
     "grade_id": "cell-b663c5f93767813b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "Z = logistic_regression.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 0]\n",
    "plt.pcolormesh(xx, yy, (Z.reshape(xx.shape) > 0.5) * 1, cmap=plt.cm.Paired)\n",
    "plt.scatter(df.x1, df.x2, c=df.y - 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "98b620f8c4d32090879b305d90724521",
     "grade": false,
     "grade_id": "cell-41bfb2bd4c75d08b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's try doing polynomial logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31733fa913ad30999e1706d55fe63031",
     "grade": false,
     "grade_id": "cell-0f9df8f4245344cf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "logistic_regression = sklearn.linear_model.LogisticRegression(C = 1e9).fit(\n",
    "    np.array([df.x1, df.x2, df.x1 ** 2, df.x2 ** 2, df.x1 ** 3, df.x2 ** 3]).T,\n",
    "    np.array(df.y) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = logistic_regression.predict_proba(np.c_[xx.ravel(), yy.ravel(),\n",
    "                                            xx.ravel() ** 2, yy.ravel() ** 2,\n",
    "                                            xx.ravel() ** 3, yy.ravel()] ** 3)[:, 0]\n",
    "plt.pcolormesh(xx, yy, (Z.reshape(xx.shape) > 0.5) * 1, cmap=plt.cm.Paired)\n",
    "plt.scatter(df.x1, df.x2, c=df.y - 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1b4a7bff83943cfa4308712ed55d5c18",
     "grade": false,
     "grade_id": "cell-803e9cbca516b734",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This is a relatively poor fit. Just like linear regression, let's try to regularize logistic regression with a ridge penalty ($\\lambda ||\\boldsymbol{\\theta}||_2^2$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "331afcba7d6b2df9efa2ef6179f90df1",
     "grade": false,
     "grade_id": "cell-5250b6c0c9c92813",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "On a sheet of paper, compute the analytic formulation of the gradient $\\nabla_{\\boldsymbol{\\theta}} E(\\boldsymbol{\\theta})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9144950a382e7fb99a25f906211add1c",
     "grade": false,
     "grade_id": "cell-7326240ec6a37751",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "*Note*: this is similar to Exercise 2 **but** the error function is now the log-loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f501c086dc10c88f5bef0179d7a9d8f9",
     "grade": true,
     "grade_id": "cell-052a5d32e545bd10",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aea4f923b3b8d3c23fb5b24fce3c9e12",
     "grade": false,
     "grade_id": "cell-a0259d90c5f7d054",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can use the $C$ parameter in `sklearn`, inversely proportional to $\\lambda$, to fit such a penalization.\n",
    "\n",
    "You can play with the parameter $C$, as well as the penalty and solver arguments. [See the documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = sklearn.linear_model.LogisticRegression(C = 0.000001, penalty='l2').fit(\n",
    "    np.array([df.x1, df.x2, df.x1 ** 2, df.x2 ** 2, df.x1 ** 3, df.x2 ** 3]).T,\n",
    "    np.array(df.y) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "880de1260b8887d2bc79864c299c9494",
     "grade": false,
     "grade_id": "cell-d199c9f91bf4e189",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "Z = logistic_regression.predict_proba(np.c_[xx.ravel(), yy.ravel(),\n",
    "                                            xx.ravel() ** 2, yy.ravel() ** 2,\n",
    "                                            xx.ravel() ** 3, yy.ravel()] ** 3)[:, 0]\n",
    "plt.pcolormesh(xx, yy, (Z.reshape(xx.shape) > 0.5) * 1, cmap=plt.cm.Paired)\n",
    "plt.scatter(df.x1, df.x2, c=df.y - 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "473b8fcd78d56be4a6ca69ecb1242429",
     "grade": false,
     "grade_id": "cell-d6a6b661bbb7f0e6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "toc-hr-collapsed": false
   },
   "source": [
    "## Weighted Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1e4a73f426ab5da886f2e13faed86fa1",
     "grade": false,
     "grade_id": "cell-af4bac9082491cae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For some regression problems, it may be helpful to give different importance to examples in the *learning set* $\\mathcal{D} = \\{(\\boldsymbol{x^{(i)}}, y^{(i)})\\}_{1 \\leq i \\leq n}$ that is to say associate a weight $\\omega^{(i)}$ to example $\\boldsymbol{x}^{(i)}$ in order to prioritize some of them and ignore some others (e.g. outliers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5093015bf8523fd8fc2b31df50b24d33",
     "grade": false,
     "grade_id": "cell-82deb75258daf7d7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Introducing these weights in the method of Least Square, the regression problem becomes:\n",
    "\n",
    "$$E(\\boldsymbol{\\theta}) = \\sum_{i=1}^n \\omega^{(i)} (y^{(i)} - \\boldsymbol{x}^{(i)} \\boldsymbol{\\theta})^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "641efa6e37df364e6cb01af697b7680b",
     "grade": false,
     "grade_id": "cell-7712759aaa6ba72f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In order to use the matrix notation, we put weights $\\omega^{(i)}$ in the diagonal of the following matrix $\\Omega$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a299354925770face478171603c261cb",
     "grade": false,
     "grade_id": "cell-71d540fb2d0901f8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "$$\n",
    "\\Omega =\n",
    "\\begin{pmatrix}\n",
    "\\omega^{(1)} & 0            & \\cdots & 0 \\\\\n",
    "0            & \\omega^{(2)} & \\cdots & 0 \\\\\n",
    "\\vdots       & \\vdots       & \\ddots & \\vdots \\\\\n",
    "0            & 0            & \\cdots & \\omega^{(n)} \\\\\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "968d07bab0979d2aade182500e34fca0",
     "grade": false,
     "grade_id": "cell-29c5ef0230f5883c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Then we can write:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f60cd10840b94e6b8262d68283e143f1",
     "grade": false,
     "grade_id": "cell-923e72243a64e67d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "$$E(\\boldsymbol{\\theta}) = (\\boldsymbol{y} - \\boldsymbol{X} \\boldsymbol{\\theta})^T \\Omega (\\boldsymbol{y} - \\boldsymbol{X} \\boldsymbol{\\theta})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ebf6bda790aa9e7fc1a9410495ff2af6",
     "grade": false,
     "grade_id": "cell-4f1c7b7e844a1ab1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "with:\n",
    "$$\n",
    "\\boldsymbol{X} = \\begin{pmatrix} 1 & x_1^{(1)} & \\dots & x_p^{(1)} \\\\ \\vdots & \\vdots & \\dots & \\vdots \\\\ 1 & x_1^{(n)} & \\dots & x_p^{(n)} \\end{pmatrix}\n",
    "\\quad \\quad\n",
    "\\boldsymbol{y} = \\begin{pmatrix} y^{(1)} \\\\ \\vdots \\\\ y^{(n)} \\end{pmatrix}\n",
    "\\quad \\quad\n",
    "\\boldsymbol{\\theta} = \\begin{pmatrix} \\theta_0 \\\\ \\vdots \\\\ \\theta_p \\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "40fb2c0ac78b61a67de77bdc3740237c",
     "grade": false,
     "grade_id": "cell-33f2eae5a9ec4421",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "toc-hr-collapsed": false
   },
   "source": [
    "### Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f82968ec0b1b66f4d606cad71d5b4cee",
     "grade": false,
     "grade_id": "cell-11cf087832e1eba3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f1a766a93f7ab4dfe5febd6a2e20648f",
     "grade": false,
     "grade_id": "cell-d57c2ce27abd8717",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "On a sheet of paper:\n",
    "- Compute the analytic formulation of the gradient $\\nabla_{\\boldsymbol{\\theta}} E(\\boldsymbol{\\theta})$\n",
    "- Compute the analytic formulation of the optimal parameter $\\boldsymbol{\\theta^*}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2d0a087047b7ae77feb7cf901867357f",
     "grade": true,
     "grade_id": "cell-db6dea2cff4057b4",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "87e67006f921b52e1e080aacdad2eda4",
     "grade": false,
     "grade_id": "cell-d1ddaf80f5424f3d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "289e53301cf3277f5f33110dfa2997e9",
     "grade": false,
     "grade_id": "cell-a8401a83c5f0f92e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Is it a convex optimization problem like *Ordinary Least Squares* ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4b53c616e0eba0459f6c2cba01739cb7",
     "grade": true,
     "grade_id": "cell-ae3362193d658468",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "00fdb6057f299e8b2e4071461b79dd1a",
     "grade": false,
     "grade_id": "cell-c33c49cb16a5ec09",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9f4237a8c151ee9cb6cf5269bf699dc3",
     "grade": false,
     "grade_id": "cell-5b83b793a648b904",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We have the following dataset and weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3be70e75c82854462b842272e490d357",
     "grade": false,
     "grade_id": "cell-9232b23cbb354822",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X = np.array([[1, 1],\n",
    "              [1, 2],\n",
    "              [1, 3],\n",
    "              [1, 4],\n",
    "              [1, 5]])\n",
    "\n",
    "y = np.array([1.8, 4.5, 3.4, 3.6, 4.2]).reshape([-1, 1])\n",
    "\n",
    "Omega = np.diag([1, 2, 3, 2, 1])\n",
    "\n",
    "Omega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d42ab5e49f87c85a957da3aef51f38d6",
     "grade": false,
     "grade_id": "cell-21a6c3f6d25fc9a6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[:,1], y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "977b5ba67a77a69b3ed75afed5d095ba",
     "grade": false,
     "grade_id": "cell-42925952786b1b54",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Complete the following Python implementation of the `weighted_least_squares()` procedure.\n",
    "It should return the optimal parameter $\\boldsymbol{\\theta^*}$ using the method of Least Square for the matrix of weights $\\Omega$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e5359867754991a635d38ba4e12610ea",
     "grade": false,
     "grade_id": "cell-bd55a21cae284d0e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Here, we expect $\\theta$ to be a Numpy array of shape `(1, 2)` (i.e. a vector of two elements)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6a99b0051122a1c11429628a93f20775",
     "grade": false,
     "grade_id": "cell-9ff0f17bcf391a48",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Numpy recall:\n",
    "- The transpose of a matrix `X` is obtained with `X.T`\n",
    "- The inverse of a matrix `X` is obtained with `np.linalg.inv(X)`\n",
    "- The product of two matrices `X` and `Y` is obtained with `np.dot(X, Y)` or `np.matmul(X, Y)` or `X @ Y`\n",
    "- The dot product of a matrix `X` and a vector `y` is obtained with `np.dot(X, y)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f172d8a45d7693f2649202a39808fbda",
     "grade": false,
     "grade_id": "cell-43283b079c1fc396",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def weighted_least_squares(X, Omega, y):\n",
    "    # theta = ...  # TO UNCOMMENT AND COMPLETE\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e935dc500bb2660afe64e4cfa82e7782",
     "grade": true,
     "grade_id": "cell-becb4b7cff3023f2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "theta = weighted_least_squares(X, Omega, y)\n",
    "assert len(theta) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "07003949e6cbebd1445e63402b1d85c1",
     "grade": false,
     "grade_id": "cell-3287a86f19b71963",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ccd8eab7390d5145c18bc5065b60d1ee",
     "grade": false,
     "grade_id": "cell-f5d7e39b2fb99f6d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Check graphically your model using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7042ec68d6a4bb9700db5e7544d2ca42",
     "grade": false,
     "grade_id": "cell-719edd179ad09de4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plot_regression_1d(X, y, theta, x_min=0, x_max=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a17fc86cede0b8e313ee980c688e4810",
     "grade": false,
     "grade_id": "cell-76e59e95f10c7355",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "04b82484c3bfe039bf686db3c16a32cd",
     "grade": false,
     "grade_id": "cell-d6d83d2ef2b2449b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Change the weights in $\\Omega$ to ignore the second point $x = 2$ (give the same weight to all other points) then recompute $\\theta$ using `weighted_least_squares()` and check the results on plots with `plot_regression_1d()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0c38c49dcefa62c1a2519ac62209b4ef",
     "grade": false,
     "grade_id": "cell-dbf64f2c60e958a8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Omega = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "theta = weighted_least_squares(X, Omega, y)\n",
    "plot_regression_1d(X, y, theta, x_min=0, x_max=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1127f3cea5fe530f044676107ee95cd1",
     "grade": true,
     "grade_id": "cell-34174ea85ab64074",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(theta) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "22e432daf3c345bda0aeeecea7cd26d1",
     "grade": false,
     "grade_id": "cell-fbc1e8a58e25ddb4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "toc-hr-collapsed": false
   },
   "source": [
    "## Nadaraya-Watson Kernel Regression (Bonus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "00c1e7e992d9c6f8bfec02b5f4ef37df",
     "grade": false,
     "grade_id": "cell-dbde0d367af37740",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Like k-Nearest Neighbors, *Nadaraya-Watson Kernel Regression* is a non-parametric model, i.e. decisions are made according to known examples from the *learning set* $\\mathcal{D} = \\{(y^{(i)}, \\boldsymbol{x^{(i)}})\\}_{1 \\leq i \\leq n}$ of $n$ examples and considering a kind of proximity relationship.\n",
    "\n",
    "With k-Nearest Neighbors, decisions are based only on the closest neighbors and other examples are simply ignored. If you remember correctly from the end of Lab 03, we used `sklearn`'s implementation of k-Nearest Neighbors and its `weights=\"distance\"` option to use the label of the nearest neighbors **proportionally to their distance from the point to predict**.\n",
    "Contrary to standard k-NN but in the same fashion as the aforementioned option, with Kernel Regression all examples $(\\boldsymbol{x}^{(i)}, y^{(i)})$ from $\\mathcal{D}$ are used to predict the label $y$ of any new point $\\boldsymbol{x}$, but their respective contribution in this prediction is weighted using a *kernel function* $K(\\boldsymbol{x}^{(i)}, \\boldsymbol{x})$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d8ccb96e35fe37afb33bfebe34d30875",
     "grade": false,
     "grade_id": "cell-2b311266839dc8ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "$$\n",
    "y\n",
    "= f(\\boldsymbol{x})\n",
    "= \\frac{\\sum^{n}_{i=1} K(\\boldsymbol{x}^{(i)}, \\boldsymbol{x}) ~ y^{(i)}}{\\sum^{n}_{j=1} K(\\boldsymbol{x}^{(j)}, \\boldsymbol{x})}\n",
    "= \\sum^{n}_{i=1} y^{(i)} \\omega^{(i)}\n",
    "$$\n",
    "\n",
    "with $\\sum^{n}_{i=1} \\omega^{(i)} = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0ae51afbc5620ed25b839f272b2b864c",
     "grade": false,
     "grade_id": "cell-2c49c814291d1f6e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Recall about the notation used here:\n",
    "- $\\boldsymbol{x}^{(i)}$ is the feature (input) vector of the $i^{\\text{th}}$ example in $\\mathcal{D}$ (and $y^{(i)}$ is its label). Beware: $\\boldsymbol{x}^{(i)}$ is not the $i^{\\text{th}}$ power of $\\boldsymbol{x}$ (we will write $\\boldsymbol{x}^{(i)2}$ for the square of $\\boldsymbol{x}^{(i)}$)!\n",
    "- $x_i$ is the value of $\\boldsymbol{x}$ on the $i^{\\text{th}}$ dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4c9fdedb97f0e3c0127c61aa2d39e9eb",
     "grade": false,
     "grade_id": "cell-caeeb2db31b2aaeb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "361d9687cfa1387d056d97e5b1ea7faa",
     "grade": false,
     "grade_id": "cell-a30b68e0c8f2e7e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "438832a224d7b9b4a7deb41dc4db3cda",
     "grade": false,
     "grade_id": "cell-dd6b5043a04876a3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Implement the Gaussian kernel $K$ in the following `gaussian_kernel()` Python function.\n",
    "\n",
    "$$\n",
    "K(\\boldsymbol{u}, \\boldsymbol{v})\n",
    "= \\exp\\left(\\frac{-||\\boldsymbol{u} - \\boldsymbol{v}||^2_2}{2 \\sigma^2} \\right)\n",
    "$$\n",
    "\n",
    "where $\\sigma$ is a parameter equal to $1$ by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e275b8f9b5a9cbb004e7871acd9d3cdc",
     "grade": false,
     "grade_id": "cell-79b3be4f27f76764",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You can assume $u$ and $v$ to be simple scalars to simplify this Python implementation (i.e. restrict yourself to regression problem with 1 dimension inputs $x \\in \\mathbb{R}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ea5accd1306c5144ea89276732ad7c84",
     "grade": false,
     "grade_id": "cell-427a677796779ec4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Recall: $e^x$ is written `math.exp(x)` in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8cb92eedbe5d93933a3a20121cc66356",
     "grade": false,
     "grade_id": "cell-3128fc886c8b2d96",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gaussian_kernel(u, v, sigma = 1.):\n",
    "    # return expression above\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5654f56b49f235caa784bc9c6a13d42e",
     "grade": true,
     "grade_id": "cell-de16122654c5da31",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert gaussian_kernel(0,0) == 1\n",
    "assert gaussian_kernel(1,0) == math.exp(-1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "10b6a023ac9022de2b0e4f809a3aebeb",
     "grade": false,
     "grade_id": "cell-c2fd67cf071eb77c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "01a62c3e416837a143aa6bd40788efa9",
     "grade": false,
     "grade_id": "cell-0f7375430d795b1a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Implement the Nadaraya-Watson kernel regression in the following `kernel_regression()` Python function.\n",
    "\n",
    "$$\n",
    "\\text{kernel_regression}(\\boldsymbol{x}, \\mathcal{D})\n",
    "= \\frac{\\sum^{n}_{i=1} K(\\boldsymbol{x}^{(i)}, \\boldsymbol{x}) ~ y^{(i)}}{\\sum^{n}_{j=1} K(\\boldsymbol{x}^{(j)}, \\boldsymbol{x})}\n",
    "= y\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e3ecbb6237bd7054ec4af534a1b4701b",
     "grade": false,
     "grade_id": "cell-ace6c2a29b8cbb05",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You can assume that $x$ is a scalar to simplify the Python implementation.\n",
    "We assume `dataset` contains examples $\\mathcal{D} = \\{(\\boldsymbol{x^{(i)}}, y^{(i)})\\}_{1 \\leq i \\leq n}$ in a Pandas DataFrame having:\n",
    "- one row per example\n",
    "- a column \"x\" containing the examples' features (only one dimension here)\n",
    "- a column \"y\" containing the examples' labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e27c266e02ddd24a3688fe54ea808c69",
     "grade": false,
     "grade_id": "cell-297c79ad23997bb6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Hint**: you can use the following `for` loop to compute $\\sum K(\\boldsymbol{x}^{(i)}, \\boldsymbol{x}) ~ y^{(i)}$: `for xi, yi in zip(df.x, df.y)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b629ed36c1933e7fa46a49041d71b286",
     "grade": false,
     "grade_id": "cell-e5f3b332a9759b1c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def kernel_regression(x, dataset):\n",
    "    # Hint: calculate numerator and denominator separately with list comprehensions\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c15bd3cc13b99c687bca8545d5c5a2b",
     "grade": true,
     "grade_id": "cell-7503a104c8598d2d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert kernel_regression(1, pd.DataFrame({\"x\": [0], \"y\": [0]})) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4369d113f3030ff8f92167a5fd890edf",
     "grade": false,
     "grade_id": "cell-1a7ed3c83d4c49a5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We have the following dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d862b1a824722654318f3145e0aadea0",
     "grade": false,
     "grade_id": "cell-8704f92203357312",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame([[2., 0.],\n",
    "                        [5., 2.],\n",
    "                        [7., 1.],\n",
    "                        [10., 2.],\n",
    "                        [14., 4.],\n",
    "                        [16., 3.],\n",
    "                        [17., 0.]], columns=['x', 'y'])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c63e8af716071bc2aba625013b8aef62",
     "grade": false,
     "grade_id": "cell-ede96d6dd3db8310",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Check your `kernel_regression()` function with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "58e323b10963408876652f1a89daed9b",
     "grade": false,
     "grade_id": "cell-72989626d17f0fb2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "x_pred = np.linspace(0., 20., 200)\n",
    "y_pred = [kernel_regression(x, dataset) for x in x_pred]\n",
    "\n",
    "ax = dataset.plot.scatter(x='x', y='y', label=\"Dataset\", figsize=(12,8))\n",
    "ax.plot(x_pred, y_pred, \"-r\", label=\"Kernel regression\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ff1529174c710882e12fc6e24a52994d",
     "grade": false,
     "grade_id": "cell-1c8f5750f1fb735b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "toc-hr-collapsed": false
   },
   "source": [
    "## Local Linear Regression (Bonus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b6239a29df8f3639fb6ba8938fb293dc",
     "grade": false,
     "grade_id": "cell-86b42eb84e710bbb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Another possible application of *Weighted Least Squares* and the *Nadaraya-Watson Kernel regression* is the *Local Linear Regression*. It uses a *Kernel* $K(\\boldsymbol{x}^{(i)}, \\boldsymbol{x})$ to define the weight $\\omega^{(i)}$ assigned to example $i$. Thus, it's a linear regression giving more importance to examples close to the point $\\boldsymbol{x}$ to predict. This means that this method does a new fit (in other words it computes a new $\\boldsymbol{\\theta}^*$) for each new point to predict! (Of course, this is much more computationally intensive than ordinary / weighted least squares)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "98f04f1fb1f822cfe62f5a4c812c66dc",
     "grade": false,
     "grade_id": "cell-89dfa0ff41443ca2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For each point $\\boldsymbol{x}$ to predict:\n",
    "1. Compute weights $\\omega^{(i)}$ assigned to examples $\\boldsymbol{x}^{(i)}$ w.r.t their distance to $\\boldsymbol{x}$: $\\omega^{(i)} = K(\\boldsymbol{x}^{(i)}, \\boldsymbol{x})$\n",
    "2. Fit Weighted Least Squares to obtain the $\\boldsymbol{\\theta}^*$ vector associated to $\\boldsymbol{x}$\n",
    "3. Return the prediction $y = \\boldsymbol{x\\theta}^*$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f90942f4e6ef0bc65d6975cd319e73d9",
     "grade": false,
     "grade_id": "cell-bde24df9ff7b8043",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5d710cd9e3a5f07ef4a542a8f2adad1f",
     "grade": false,
     "grade_id": "cell-a340bb8bbfe87241",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We have the following dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27bcc7eeade5a8d2a56b3207a4a9a446",
     "grade": false,
     "grade_id": "cell-ae1d91b439727e91",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "dataset = gen_1d_polynomial_regression_samples(n_samples=30)\n",
    "\n",
    "plot_1d_regression_samples(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bca8cf24a3e803093cb28adb3223f12e",
     "grade": false,
     "grade_id": "cell-86f880531d9787bc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "04bba18d258bc431b3f370beb72a92d5",
     "grade": false,
     "grade_id": "cell-bf65bd0bed0f4e4a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Complete the following Python implementation of the `locally_weighted_regression()` procedure defined above.\n",
    "It should use the previously implemented `gaussian_kernel()` function (with `sigma=0.1`) and `weighted_least_squares()` function. It should return the predicted label $y$ corresponding to one input $\\boldsymbol{x}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4ce7767c8d40ef8f094078300c2ed5f",
     "grade": false,
     "grade_id": "cell-d9098c7d1cfbff50",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def locally_weighted_regression(x, dataset, sigma=0.1):    \n",
    "    # Compute a weight wi for each example xi of the dataset: the closer xi is to x, the smaller wi is\n",
    "    \n",
    "    # wi = ...                                      # <- **TODO: UNCOMMENT AND COMPLETE**\n",
    "    # Omega = ...                                   # <- **TODO: UNCOMMENT AND COMPLETE**\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Fit weighted least squares to obtain theta\n",
    "    intercept = np.ones(shape=len(dataset.x))\n",
    "    X = np.array([intercept, dataset.x]).T\n",
    "    y = dataset.y.values.reshape([-1, 1])\n",
    "    theta = weighted_least_squares(X, Omega, y)\n",
    "    \n",
    "    # Return prediction y = f(x)\n",
    "    # y = ...                                       # <- **TODO: UNCOMMENT AND COMPLETE**\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c6f44d9c3c44f553ace9bc163731fa41",
     "grade": true,
     "grade_id": "cell-10ab4b7e6f6035f2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(locally_weighted_regression(0, dataset, sigma=0.1)) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2474132e09a48455f02bdd824a45fec4",
     "grade": false,
     "grade_id": "cell-5aad676803ac0888",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Generate \"test\" points in the ~ [0;1.5] support of the data previously generated \n",
    "x_pred = np.linspace(0., 1.5, 100)\n",
    "# Predict the target y of these test points using the Locally-weighted regression model\n",
    "y_pred = [locally_weighted_regression(x, dataset, sigma=0.1) for x in x_pred]\n",
    "# Plot the results\n",
    "ax = dataset.plot.scatter(x='x', y='y', figsize=(16, 8))\n",
    "ax.plot(x_pred, y_pred);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9887d94a3bbbe8a0b31ff2783aa23a65",
     "grade": false,
     "grade_id": "cell-90454093b5e92837",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1d5bdcbe46edb318443d30feed19d89d",
     "grade": false,
     "grade_id": "cell-2a172b9bddb13f52",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "What happens when you change the value of the variable `sigma` parameter (try e.g. `sigma=0.3`)?\n",
    "Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c623b8f11f1232a4f589e9374d011ba8",
     "grade": true,
     "grade_id": "cell-2142318e7a18fd7c",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "x_pred = np.linspace(0., 1.5, 100)\n",
    "# y_pred = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "ax = dataset.plot.scatter(x='x', y='y', figsize=(16, 8))\n",
    "ax.plot(x_pred, y_pred);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a80ab2ca75b389623fb4a5bca384a401",
     "grade": true,
     "grade_id": "cell-1b8cb8a34b0c7169",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ea3483a828b72974153302623ff274d2",
     "grade": false,
     "grade_id": "cell-76c8b6180373d3b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "41c719df98f0c3954c23cde685e13c9b",
     "grade": false,
     "grade_id": "cell-33d2d5033e114093",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Can we use Local Linear Regression to forecast time series as it was asked in the exercise 7 of the lab session 2? (You can try it out in the cells below.) Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ed32f62b262425031327eccf71a721a3",
     "grade": false,
     "grade_id": "cell-e3752b249fe01679",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "URL = \"https://raw.githubusercontent.com/adimajo/CSE204-2021/master/data/natural_gas_co2_emissions_for_electric_power_sector.csv\"\n",
    "df = pd.read_csv(URL, parse_dates=[0])\n",
    "\n",
    "df['x'] = df.index\n",
    "df['y'] = df.co2_emissions\n",
    "\n",
    "df[['x','y']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c37e59a9bc5cea13683791cfae86dd11",
     "grade": true,
     "grade_id": "cell-c82f1c7af35c3f14",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "x_pred = np.linspace(0., len(df) + 5, 1000)\n",
    "# y_pred = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "ax = df.plot.scatter(x='x', y='y', figsize=(16, 8))\n",
    "ax.plot(x_pred, y_pred, \"-r\", label=\"Prediction\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "22e5968a1b3697a73e782282b2d44099",
     "grade": true,
     "grade_id": "cell-794205722927aee7",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSE204",
   "language": "python",
   "name": "cse204"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
