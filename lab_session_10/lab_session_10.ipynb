{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "yw6trru89_zZ",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ac002feb3070f02116cb96010015bd27",
     "grade": false,
     "grade_id": "cell-a474f0130611ac2d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# CSE204 - Introduction to Machine Learning - Lab Session 10: Dimensionality Reduction with Principal Components Analysis (PCA)\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/adimajo/CSE204-2021/master/data/logo.jpg\" style=\"float: left; width: 15%\" />\n",
    "\n",
    "[CSE204-2021](https://moodle.polytechnique.fr/course/view.php?id=12838) Lab session #10\n",
    "\n",
    "J.B. Scoggins - Adrien Ehrhardt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "98f6bb186b748e21c76893e79fd417fe",
     "grade": false,
     "grade_id": "cell-3518fb9008a3444d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this lab, you will get hands-on experience with dimension reduction using Principal Component Analysis. The goal of dimension reduction is to find a suitable transformation which converts a high-dimensional space into a smaller feature space, such that the important information is not lost, but the visualization and interpretability are easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "ziXG8VAl9_zd",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d6eee2b635b9b88b3b819d950ecba34f",
     "grade": false,
     "grade_id": "cell-620e8cbad8f79c88",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.datasets.mnist as mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras import Model\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import decomposition\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "oTVnpKTn9_zf",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "29335ac23c7ab1c2702226a1d4dd3514",
     "grade": false,
     "grade_id": "cell-300d5071dadb1cda",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 1: The original MNIST Dataset\n",
    "\n",
    "We will use the MNIST digits dataset throughout this lab session. The original MNIST dataset provides 60000 28x28 pixel grayscale training images of hand-written digits 0-9. The images are labeled with integer values 0-9. The training set has become the _de facto_ image classification example due to its small size.\n",
    "\n",
    "In this exercise, we are not interested in classifying images of digits. Instead, we will think of the images as defining a 28x28 = 784 element feature space. In this context, we are interested in transforming the 784 parameters into a smaller set of transformed coordinates.  \n",
    "\n",
    "**Exercise 1.1:** Before continuing to the next section, use the keras datasets module to load the MNIST dataset, normalize it, and get to know how it is structured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "aol51DVe9_zg",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d73ddf7261e13a729b6a3e8523e2d24",
     "grade": false,
     "grade_id": "cell-5578dbe82b796689",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# x_train, ..., = mnist...  # <- TO UNCOMMENT AND COMPLETE\n",
    "# x_train = x_train / ...   # <- TO UNCOMMENT AND COMPLETE\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f2a4d69d73f70ea9a6358d2bb96d7711",
     "grade": true,
     "grade_id": "cell-5c8e789fbb35b349",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3fe5fb92e166c8006d5cbf3b5882b3ea",
     "grade": false,
     "grade_id": "cell-20f834cafc7b29ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- Inspect the dataset. What is the shape of x_train and y_train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "754fcfde2250967a5ba5353953c74e05",
     "grade": true,
     "grade_id": "cell-9d6cdf3c9264786d",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a666916d31796ae82be852254557f53a",
     "grade": false,
     "grade_id": "cell-aaa8fa0844b590da",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- Plot a few images using `matplotlib.pyplot` to see what they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c2fdf50b183b167c34a54561b963a9b",
     "grade": true,
     "grade_id": "cell-e26784650bc5c284",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "3gkFxMdF9_zj",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6971bd9b7e00a69cc1578f88e8dea377",
     "grade": false,
     "grade_id": "cell-4c52185250d375c5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 2: Principal Component Analysis (PCA)\n",
    "\n",
    "The goal of PCA is to perform an orthogonal transformation which converts a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables, called _principal components_. This can be thought of as fitting a $p$-dimensional ellipsoid to the observations.  \n",
    "\n",
    "Let's consider a dataset $X\\in R^{n\\times p}$, where $n$ is the number of observations and $p$ the number of variables.  PCA transforms $X$ into a new coordinate system (new variable set), such that the greatest variance in the data is captured in the first coordinate, and then the second, and so on.  More specifically, the transformed coordinates $T \\in R^{n\\times p}$ are written as a linear combination of the original dataset,\n",
    "\n",
    "$$ T = X W, $$\n",
    "\n",
    "where $W \\in R^{p\\times p}$ is the transformation matrix. The first column of $W$, denoted as $w_1$, is constructed to maximize the variance of the transformed coordinates.\n",
    "\n",
    "$$ w_1 = \\underset{\\|w\\|=1}{\\operatorname{argmax}} \\sum_{i=1}^{n} (t_1)_i^2 = \\underset{\\|w\\|=1}{\\operatorname{argmax}} \\| X w \\|_2^2 = \\underset{\\|w\\|=1}{\\operatorname{argmax}} \\frac{w^T X^T X w}{w^T w} $$\n",
    "\n",
    "The ratio in the last term is known as the _Rayleigh quotient_. It is well known that for the positive, semidefinite matrix $X^T X$, the largest value of the Rayleigh quotient is given as the largest eigenvalue of the matrix, where $w$ is eigenvector associated with that eigenvalue.\n",
    "\n",
    "The remaining columns of $W$ can be found by finding the the next orthogonal linear combination which maximizes the variance of the data, minus the previously transformed coordinates.\n",
    "\n",
    "$$ w_k = \\underset{\\|w\\|=1}{\\operatorname{argmax}} \\| (X - \\sum_{s=1}^{k-1} X w_s w_s^T) w \\|^2_2 $$\n",
    "\n",
    "Practically, the columns of $W$ are typically computed as the eigenvectors of $X^T X$ ordered by their corresponding eigenvalues in descending order.\n",
    "\n",
    "### Singular Value Decomposition\n",
    "\n",
    "The Singular Value Decomposition of a matrix $X \\in R^{n\\times p}$ is given as\n",
    "\n",
    "$$ X = U \\Sigma W^T, $$\n",
    "\n",
    "where $\\Sigma \\in R^{n\\times p}$ is a rectangular diagonal matrix of positive values known as the the singular values, of $X$, $\\sigma(X)$, and $U \\in R^{n\\times n}$ and $W \\in R^{p\\times p}$ are orthonormal matrices, whose columns are the left and right (respectively) singular vectors of the matrix $X$. Using this decomposition, we can easily see that\n",
    "\n",
    "$$ X^T X = W \\hat{\\Sigma} W^T, $$\n",
    "\n",
    "where $\\hat{\\Sigma}$ is a square diagonal matrix of the squared singular values of $X$. Comparing this to the eigenvalue decomposition of $X^T X = Q \\Lambda Q^T$, we see that the singular values of $X$ represent the square-root of the eigenvalues of $X^T X$, and the singular vectors of $X$ are simply the eigenvectors of $X^T X$.  Therefore, we can perform PCA on a data matrix $X$ by computing its right singular vector matrix, $W$.\n",
    "\n",
    "### Dimensionality Reduction\n",
    "\n",
    "We can reduce the dimensionality of our data by truncating the transformed variables to include only a subset of those variables with the highest variance. For example, if we keep the first $L <= p$ variables, the reduced transformation reads\n",
    "\n",
    "$$ T_L = X W_L, $$\n",
    "\n",
    "where $W_L \\in R^{n\\times L}$ is the eigenvector matrix as before, but taking only the first $L$ columns.  This technique has been widely used to reduce the dimension of large-dimensioned datasets by accounting for the directions of largest variance in the data, while neglecting the other directions. In addition, this can also be used to remove noise from a dataset, in which it is assumed that the noise accounts for a small degree of variance, compared to the true underlying parameterization. Finally, using PCA to find the 2 highest varying parameters can also allow us to visualize a high-dimensional dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "08fd8c2dd0b39d927ae4f304af7674e4",
     "grade": false,
     "grade_id": "cell-5ff75c3bb2fd1ceb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### An example with `sklearn` to get you started: the `iris` dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "94777dd1f9c3610f275f5bbb8d3efedc",
     "grade": false,
     "grade_id": "cell-9bdb4fec5f347ee3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad8084ead577740f80b9088b1ea8a626",
     "grade": false,
     "grade_id": "cell-6ec3f012088a2e13",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "print(\"Shape of X:\", X.shape, \"\\n\")\n",
    "print(\"The 4 features are:\", iris.feature_names, \"\\n\")\n",
    "smpl = np.random.randint(0, X.shape[0], size=10)\n",
    "print(\"10 random rows of X:\")\n",
    "print(X[smpl, :], \"\\n\")\n",
    "print(\"Their associated label:\")\n",
    "print(y[smpl], \"\\n\")\n",
    "print(\"The label names associated to 0, 1 and 2 resp.\")\n",
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "20e49d294fe0a526b3c4fc5354c21ab6",
     "grade": false,
     "grade_id": "cell-5aad68ab711eacd7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's visualize the two first coordinates and the labels.\n",
    "\n",
    "Would we be able to directly predict the labels, *i.e.* draw linear decision boundaries for each class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98ff391473151a849a748335949a0931",
     "grade": false,
     "grade_id": "cell-fec3012a17505db3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "\n",
    "plt.scatter(X[:, 0], \n",
    "            X[:, 1], \n",
    "            c=y, \n",
    "            cmap=plt.cm.Set1,\n",
    "            edgecolor='k')\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bf8cef28781aaf796ae124a10f14f041",
     "grade": false,
     "grade_id": "cell-fae85d968c19e3fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "... No, not really; let's try in 3D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca25563509d5db824647c64ba784ebe2",
     "grade": false,
     "grade_id": "cell-deb2c1d826d17482",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = Axes3D(fig, elev=-150, azim=110, auto_add_to_figure=False)\n",
    "fig.add_axes(ax)\n",
    "ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=y,\n",
    "           cmap=plt.cm.Set1, edgecolor='k', s=40)\n",
    "ax.set_title(\"First three coordinates\")\n",
    "ax.set_xlabel(iris.feature_names[0])\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.set_ylabel(iris.feature_names[1])\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.set_zlabel(iris.feature_names[2])\n",
    "ax.w_zaxis.set_ticklabels([])\n",
    "for name, label in [('Setosa', 0), ('Versicolour', 1), ('Virginica', 2)]:\n",
    "    ax.text3D(X[y == label, 0].mean(),\n",
    "              X[y == label, 1].mean(),\n",
    "              X[y == label, 2].mean(),\n",
    "              name,\n",
    "              horizontalalignment='center',\n",
    "              bbox=dict(alpha=.5, edgecolor='w', facecolor='w'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "acff69370728281bbea2fd9919f7c49a",
     "grade": false,
     "grade_id": "cell-6b6a2ab5535f3cdf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The setosa are well apart, but not the other two classes. Unfortunately, it would be hard to represent a 4D graph... So that's where PCA comes in handy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "13a0d5d3d789d3bf760e860f0064f916",
     "grade": false,
     "grade_id": "cell-e89e3124a7e61b5d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's perform PCA with `sklearn` and represent the data projected unto the 3 first axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2322531e5e25872b06e9ea6cafb27816",
     "grade": false,
     "grade_id": "cell-6b99fca39f6e6b93",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.clf()\n",
    "ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134, auto_add_to_figure=False)\n",
    "fig.add_axes(ax)\n",
    "\n",
    "plt.cla()\n",
    "pca = decomposition.PCA(n_components=3)\n",
    "pca.fit(X)\n",
    "X_transformed = pca.transform(X)\n",
    "\n",
    "ax.set_title(\"First three principal components\")\n",
    "ax.set_xlabel(\"First principal component\")\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.set_ylabel(\"Second principal component\")\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.set_zlabel(\"Third principal component\")\n",
    "ax.w_zaxis.set_ticklabels([])\n",
    "\n",
    "for name, label in [('Setosa', 0), ('Versicolour', 1), ('Virginica', 2)]:\n",
    "    ax.text3D(X_transformed[y == label, 0].mean(),\n",
    "              X_transformed[y == label, 1].mean(),\n",
    "              X_transformed[y == label, 2].mean(), name,\n",
    "              horizontalalignment='center',\n",
    "              bbox=dict(alpha=.5, edgecolor='w', facecolor='w'))\n",
    "\n",
    "ax.scatter(X_transformed[:, 0], X_transformed[:, 1], X_transformed[:, 2], \n",
    "           c=y, cmap=plt.cm.Set1,\n",
    "           edgecolor='k')\n",
    "\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.w_zaxis.set_ticklabels([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eaddc0e8b9fb193962df541382da2f7c",
     "grade": false,
     "grade_id": "cell-67a27ff122aa6a90",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The 3 types of flowers seem well separated. Is it also the case in 2D now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d9bfa94aab04953c7c26c550c141098",
     "grade": false,
     "grade_id": "cell-e16b6582248db9bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "x_min, x_max = X_transformed[:, 0].min() - .5, X_transformed[:, 0].max() + .5\n",
    "y_min, y_max = X_transformed[:, 1].min() - .5, X_transformed[:, 1].max() + .5\n",
    "\n",
    "plt.scatter(X_transformed[:, 0], \n",
    "            X_transformed[:, 1], \n",
    "            c=y, \n",
    "            cmap=plt.cm.Set1,\n",
    "            edgecolor='k')\n",
    "plt.xlabel('First principal component')\n",
    "plt.ylabel('Second principal component')\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bd9dd06301a21fc0cb1816c149ed5096",
     "grade": false,
     "grade_id": "cell-d8d3d923b18a128d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Perfect! It seems we were able to \"compress\" enough information from the 4 original features into 2 linear combinations of these features: the two first principal components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "46630c3717bc0360e990f580a05c00a8",
     "grade": false,
     "grade_id": "cell-461339a781b603bf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### The real deal: the `MNIST` dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "73488412c693c4f9afbb279c8a34d5d3",
     "grade": false,
     "grade_id": "cell-9e5ad18dced5d1dd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Exercise 2.1:** Visualize the MNIST dataset in 2 dimensions.\n",
    "\n",
    "- Reshape the array `X` to 2D with n = 60000 and p = 28 x 28 = 784."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "zH4l04-a9_zk",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e98717bb845ccb9cb12bb5eedc94d20f",
     "grade": false,
     "grade_id": "cell-64064a1bfedd649e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# x_train_reshaped = ...  # <- TO UNCOMMENT AND COMPLETE\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe5f416e54c912ef091099dee6c4d161",
     "grade": true,
     "grade_id": "cell-092f7fd83b51628c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "42277b903bfe4561baa951779d77e089",
     "grade": false,
     "grade_id": "cell-f813bb52d5852cad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- Use numpy to [compute the SVD](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.svd.html) of the MNIST images. Recall the notation of $U$, $\\Sigma$ and $W^T$ [introduced above](#Step-2:-Principal-Component-Analysis-(PCA)). (Yes, this might take some time... If you get a `MemoryError`, read the documentation carefully)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b318861a06a7b459d5327d14c4c96f86",
     "grade": false,
     "grade_id": "cell-fcb69df87c9af17c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# u, sigma, w_transpose = ...  # <- TO UNCOMMENT AND COMPLETE\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1c8de6a0a91a9298103a5e09c053db96",
     "grade": true,
     "grade_id": "cell-7bd8ec43f8d6e686",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5cf784011fb0157a7c79a750afaecd77",
     "grade": false,
     "grade_id": "cell-1f6b864d27293581",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- Compute the first two principal components by truncating the eigenvector matrix (*i.e.* the two first columns of $W$ in the [notations introduced above](#Step-2:-Principal-Component-Analysis-(PCA))).\n",
    "- Multiply the original data by the previous result (*i.e.* the the two first principal components): you obtain the projected data (onto the new PCA space), in other words $T_L$ for $L=2$ in the [notations introduced above](#Step-2:-Principal-Component-Analysis-(PCA))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "688edbedc7f7d09c3e7143a2a4ff70c9",
     "grade": false,
     "grade_id": "cell-f910d20d3bbc5e4d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# T_2 = ...  # <- TO UNCOMMENT AND COMPLETE\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a03ddfe6d3b9fbab9a6d7137e073fa9",
     "grade": true,
     "grade_id": "cell-efecb99454cb2979",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b3d50c1161001f518663c46da495e05e",
     "grade": false,
     "grade_id": "cell-ecbd0921e0b0cef9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- Plot the original data projected onto the two first principal components using a scatter plot with [`matplotlib.pyplot.scatter`](https://matplotlib.org/3.5.0/api/_as_gen/matplotlib.pyplot.scatter.html), and the image labels to color the markers.\n",
    "\n",
    "(*Hint*: the plot might be easier to interpret if you represent fewer points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb5c4f3883aeb205e6cd24485b56b30f",
     "grade": true,
     "grade_id": "cell-0ba71310287feb98",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# plt.scatter(..., cmap='rainbow')  # <- TO UNCOMMENT AND COMPLETE\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9f509086f3b7ab38af2e979fbc7e3fe5",
     "grade": false,
     "grade_id": "cell-35a0fb211eb89998",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- What do you notice about how the data is presented in the plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7dded713a1ff80ddd7761e16790ecad0",
     "grade": true,
     "grade_id": "cell-092354c82c909992",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a8b1f78599e9818bf83c47491b519ebe",
     "grade": false,
     "grade_id": "cell-1e2a9aa00ad5d015",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- Which images form a tight cluster in the reduced space?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2370307edcaa22f4f2017a1073ba6dd0",
     "grade": true,
     "grade_id": "cell-5a9c83edfae65707",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "eszpfZea9_zm",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cf4a9136dab406fa00fdc91927e51441",
     "grade": false,
     "grade_id": "cell-393dac907407f302",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Scree Plot\n",
    "\n",
    "It is not always clear how many principal components are necessary to accurately represent the high-dimensional space.  There are two widely used methods to help us get a sense of the number variables required.  The first is called a Scree plot, which plots the eigenvalues of $X^T X$ in descending order.  Since the eigenvalues represent the degree of variance in the corresponding principal components, such a plot can tell use how many components are needed before we reach diminishing returns.\n",
    "\n",
    "**Exercise 2.2:** Plot the Scree plot for the MNIST data. _Hint_: use the `sigma` matrix of singular values of $X$ computed above.\n",
    "- How many principal components are needed to represent most of the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "X4XVVYsG9_zn",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c09642fa85d9a9e2961c99c24dae33c1",
     "grade": true,
     "grade_id": "cell-e5cc5173dd01d628",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7afc1b6e2eb09215973165528d8c2974",
     "grade": true,
     "grade_id": "cell-3b17479a824d65ba",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "BPnoC5F09_zp",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "457eb8135267a9248f81753719b92993",
     "grade": false,
     "grade_id": "cell-1726eec4aab83ef6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Total Variance Explained\n",
    "\n",
    "Another method is called _Total Variance Explained_.  In this method, we plot the cumulative sum of the eigenvalues and choose the number of components which give us a certain percentage fo the total variance.\n",
    "\n",
    "**Exercise 2.3:** Plot the cumulative sum of the eigenvalues.\n",
    "- Plot a horizontal line at 95% of the total sum.\n",
    "- Based on this, how many components are needed to capture 95% of the variance?\n",
    "- How does this compare to the Scree plot result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "Z53KPM1F9_zq",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c98ec6e6759782536218d714fd86dd2",
     "grade": true,
     "grade_id": "cell-a5222e0e13103b9a",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9000ecb826d511f6a4ef82097f2207a6",
     "grade": true,
     "grade_id": "cell-1e45c6a8676c3983",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "yTRY_Mzw9_zs",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3bf91701513a665024e64f9dd1dbc3f0",
     "grade": false,
     "grade_id": "cell-cf39ce4971003a6b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Reconstruct Images\n",
    "\n",
    "Now that we have an idea of how many principal components are necessary, let's use them to encode the images in a smaller set of features, which we can then decode to reconstruct the images from the lower-dimensional space.  Recall that based on the PCA transformation, we can compute the reconstructed images with\n",
    "\n",
    "$$ \\hat{X} = (X W_L) W_L^T $$\n",
    "\n",
    "**Exercise 2.4:** Plot original and reconstruct images.\n",
    "- Create a grid of images using `pyplot.subplots` and `imshow`.\n",
    "  - In the first row, plot the first 5 images of the dataset.\n",
    "  - In the next 4 rows, plot reconstructions of the images using the first 5, 15, 30, and 100 principal component vectors.\n",
    "- How do the reconstructed images compare with the originals as you increase the size of the reduced space?\n",
    "\n",
    "Note that once we have computed the transformation matrix $W$, we essentially have a compression scheme to convert our images into a compressed format.  From this perspective, using the first 5, 10, 30, and 100 principal components is equivalent to compressing the data at a rate of 156:1, 78:1, 26:1, and 8:1, respectively.  By contrast, JPEG image compression can obtain compression ratios of 23:1 with reasonable image quality, surpassing the quality of reconstructions with PCA.  For that reason, PCA is not really used for image compression, but it has been used in a number of other fields, particularly in physics and engineering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "iVi8wfbv9_zu",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2130a6bc6089f72b10b7ee6dcb64838b",
     "grade": true,
     "grade_id": "cell-eccb6e16ec08a07e",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copie de Lab10.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/jbscoggi/teaching/blob/master/Polytechnique/CSE204/Lab10.ipynb",
     "timestamp": 1576227388467
    }
   ]
  },
  "kernelspec": {
   "display_name": "CSE204",
   "language": "python",
   "name": "cse204"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
