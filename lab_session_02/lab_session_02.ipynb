{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "02e340020fe8ee77b93b27d7b4f11078",
     "grade": false,
     "grade_id": "cell-af5a035c54cd45c0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "meta",
     "toc_en"
    ],
    "toc-hr-collapsed": false
   },
   "source": [
    "# CSE204 - Introduction to Machine Learning - Lab Session 2: parametric models\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/adimajo/CSE204-2021/master/data/logo.jpg\" style=\"float: left; width: 15%\" />\n",
    "\n",
    "[CSE204-2021](https://moodle.polytechnique.fr/course/view.php?id=12838) Lab session #02\n",
    "\n",
    "Jérémie DECOCK - Adrien EHRHARDT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "76a1cd207888c5fe54689f8e92ddbc62",
     "grade": false,
     "grade_id": "cell-8936d2d1fab8ae72",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Objectives\n",
    "\n",
    "- Introduction to parametric models\n",
    "- Calculate by hand a linear regression\n",
    "- Implement a linear regressor using gradient descent\n",
    "- Linear regression with Scikit Learn\n",
    "- Implement a polynomial regressor with Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f89eb2828604ed6d2572df3fec393df0",
     "grade": false,
     "grade_id": "cell-e93c2d0251fc72af",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Imports and tool functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "04f8080c0c56c2a5cc020ce62102681b",
     "grade": false,
     "grade_id": "cell-a6a109c8cb7dee00",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b731e30a3d49d2606e8b96a01e6913df",
     "grade": false,
     "grade_id": "cell-6656a058fae3c466",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.colors as colors\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "\n",
    "\n",
    "def gen_1d_linear_regression_samples(n_samples: int = 20) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate one-dimensional linear regression samples\n",
    "\n",
    "    :param int n_samples: number of samples to generate\n",
    "    \"\"\"\n",
    "    x = np.random.uniform(low=-10., high=10., size=n_samples)\n",
    "    y = 2. * x + 3. + np.random.normal(scale=2., size=x.shape)\n",
    "    df = pd.DataFrame(np.array([x, y]).T, columns=['x', 'y'])\n",
    "    df = sklearn.utils.shuffle(df).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def gen_1d_polynomial_regression_samples(n_samples: int = 15) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate one-dimensional polynomial regression samples\n",
    "\n",
    "    :param int n_samples: number of samples to generate\n",
    "    \"\"\"\n",
    "    x = np.random.uniform(low=0., high=10., size=n_samples)\n",
    "    y = 3. - 2. * x + x ** 2 - x ** 3 + np.random.normal(scale=10., size=x.shape)\n",
    "    df = pd.DataFrame(np.array([x, y]).T, columns=['x', 'y'])\n",
    "    df = sklearn.utils.shuffle(df).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_1d_regression_samples(dataframe: pd.DataFrame, model=None):\n",
    "    \"\"\"\n",
    "    Plot the regression samples in one-D with the predictions if model is provided\n",
    "\n",
    "    :param pandas.DataFrame dataframe: a dataframe containing the :code:`x` feature and\n",
    "        :code:`y` dependent feature to regress on.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    \n",
    "    df = dataframe.copy()  # make an alias\n",
    "    \n",
    "    ERROR_MSG1 = \"The `dataframe` parameter should be a Pandas DataFrame having the following columns: ['x', 'y']\"\n",
    "    assert df.columns.values.tolist() == ['x', 'y'], ERROR_MSG1\n",
    "    \n",
    "    if model is not None:\n",
    "        # Compute the model's prediction\n",
    "        x_pred = np.linspace(df.x.min(), df.x.max(), 100).reshape(-1, 1)\n",
    "        y_pred = model.predict(x_pred)\n",
    "        df_pred = pd.DataFrame(np.array([x_pred.flatten(), y_pred.flatten()]).T, columns=['x', 'y'])\n",
    "        df_pred.plot(x='x', y='y', style='r--', ax=ax)\n",
    "\n",
    "    # Plot also the training points\n",
    "    df.plot.scatter(x='x', y='y', ax=ax)\n",
    "    delta_y = df.y.max() - df.y.min()\n",
    "    plt.ylim((df.y.min() - 0.15 * delta_y,\n",
    "              df.y.max() + 0.15 * delta_y))\n",
    "\n",
    "\n",
    "def plot_ex2(X: np.array, y: np.array, theta_0: float = None, theta_1: float = None):\n",
    "    \"\"\"\n",
    "    Puts X and y in a dataframe and plot the result; expects one-dimensional inputs X and y.\n",
    "    If theta_0 and theta_1 are provided, calculate and plot y_hat as well.\n",
    "\n",
    "    :param numpy.array X: one-dimensional regression feature\n",
    "    :param numpy.array y: one-dimensional target feature\n",
    "    :param float theta_0: constant linear regression coefficient\n",
    "    :param float theta_1: linear regression coefficient associated with X\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(np.array([X, y]).T, columns=['x', 'y'])\n",
    "\n",
    "    ax = df.plot.scatter(x=\"x\", y=\"y\")\n",
    "\n",
    "    if theta_0 is not None and theta_1 is not None:\n",
    "        x = np.array([1, 9])\n",
    "        y = theta_0 + theta_1 * x\n",
    "\n",
    "        ax.plot(x, y, \"--r\")\n",
    "\n",
    "\n",
    "def plot_ex4(X: np.array, y: np.array, theta_1: float = None, theta_2: float = None):\n",
    "    \"\"\"\n",
    "    Puts X and y in a dataframe and plot the result; expects one-dimensional inputs X and y.\n",
    "    If theta_1 and theta_2 are provided, calculate and plot y_hat = theta_1 * x + theta_2 * x**2 as well.\n",
    "\n",
    "    :param numpy.array X: one-dimensional regression feature\n",
    "    :param numpy.array y: one-dimensional target feature\n",
    "    :param float theta_1: linear regression coefficient associated with X\n",
    "    :param float theta_2: linear regression coefficient associated with X**2\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(np.array([X, y]).T, columns=['x', 'y'])\n",
    "    ax = df.plot.scatter(x=\"x\", y=\"y\")\n",
    "\n",
    "    if theta_1 is not None and theta_2 is not None:\n",
    "        x = np.linspace(0, 6, 50)\n",
    "        y = theta_1 * x + theta_2 * x**2\n",
    "        ax.plot(x, y, \"--r\")\n",
    "\n",
    "\n",
    "def plot_contour_2d_solution_space(func,\n",
    "                                   fig=None,\n",
    "                                   ax=None,\n",
    "                                   show=True,\n",
    "                                   theta_min: np.array = -np.ones(2),\n",
    "                                   theta_max: np.array = np.ones(2),\n",
    "                                   theta_star: np.array = None,\n",
    "                                   theta_visited: np.array = None,\n",
    "                                   title: str = \"\"):\n",
    "    \"\"\"\n",
    "    Plot points visited during the execution of an optimization algorithm.\n",
    "\n",
    "    \"\"\"\n",
    "    if (fig is None) or (ax is None):\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    if theta_visited is not None:\n",
    "        theta_min = np.amin(np.hstack([theta_min.reshape([-1, 1]), theta_visited]), axis=1)\n",
    "        theta_max = np.amax(np.hstack([theta_max.reshape([-1, 1]), theta_visited]), axis=1)\n",
    "\n",
    "    x1_space = np.linspace(theta_min[0], theta_max[0], 200)\n",
    "    x2_space = np.linspace(theta_min[1], theta_max[1], 200)\n",
    "    x1_mesh, x2_mesh = np.meshgrid(x1_space, x2_space)\n",
    "    zz = func(np.array([x1_mesh.ravel(), x2_mesh.ravel()])).reshape(x1_mesh.shape)\n",
    "\n",
    "    ############################\n",
    "\n",
    "    if theta_star is not None:\n",
    "        min_value = func(theta_star)\n",
    "    else:\n",
    "        min_value = zz.min()\n",
    "        \n",
    "    max_value = zz.max()\n",
    "    levels = np.logspace(0.1, 3., 5)\n",
    "    im = ax.pcolormesh(x1_mesh,\n",
    "                       x2_mesh,\n",
    "                       zz,\n",
    "                       vmin=min_value,\n",
    "                       vmax=max_value,\n",
    "                       shading='gouraud',\n",
    "                       cmap='gnuplot2')\n",
    "\n",
    "    plt.colorbar(im, ax=ax)\n",
    "\n",
    "    cs = plt.contour(x1_mesh,\n",
    "                     x2_mesh,\n",
    "                     zz,\n",
    "                     levels,\n",
    "                     linewidths=(2, 2, 2, 2, 3),\n",
    "                     linestyles=('dotted', '-.', 'dashed', 'solid', 'solid'),\n",
    "                     alpha=0.5,\n",
    "                     colors='white')\n",
    "    ax.clabel(cs, inline=False, fontsize=12)\n",
    "\n",
    "    ############################\n",
    "\n",
    "    if theta_visited is not None:\n",
    "        ax.plot(theta_visited[0],\n",
    "                theta_visited[1],\n",
    "                '-og',\n",
    "                alpha=0.5,\n",
    "                label=\"$visited$\")\n",
    "\n",
    "    ############################\n",
    "\n",
    "    if theta_star is not None:\n",
    "        sc = ax.scatter(theta_star[0],\n",
    "                        theta_star[1],\n",
    "                        c='red',\n",
    "                        label=r\"$\\theta^*$\")\n",
    "        sc.set_zorder(10)        # put this point above every thing else\n",
    "\n",
    "    ############################\n",
    "\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.set_xlabel(r\"$\\theta_0$\", fontsize=16)\n",
    "    ax.set_ylabel(r\"$\\theta_1$\", fontsize=16)\n",
    "    ax.legend(fontsize=16)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def plot_2d_solution_space(func,\n",
    "                           fig=None,\n",
    "                           ax=None,\n",
    "                           show=True,\n",
    "                           theta_min=-np.ones(2),\n",
    "                           theta_max=np.ones(2),\n",
    "                           theta_star=None,\n",
    "                           angle_view=None,\n",
    "                           title=\"\"):\n",
    "    \"\"\"Plot points visited during the execution of an optimization algorithm.\"\"\"\n",
    "    if fig is None or ax is None:\n",
    "        fig = plt.figure(figsize=(12, 8))\n",
    "        ax = axes3d.Axes3D(fig)\n",
    "\n",
    "    if angle_view is not None:\n",
    "        ax.view_init(angle_view[0], angle_view[1])\n",
    "\n",
    "    x1_space = np.linspace(theta_min[0], theta_max[0], 100)\n",
    "    x2_space = np.linspace(theta_min[1], theta_max[1], 100)\n",
    "\n",
    "    x1_mesh, x2_mesh = np.meshgrid(x1_space, x2_space)\n",
    "\n",
    "    zz = func(np.array([x1_mesh.ravel(), x2_mesh.ravel()])).reshape(x1_mesh.shape)\n",
    "\n",
    "    ############################\n",
    "\n",
    "    surf = ax.plot_surface(x1_mesh,\n",
    "                           x2_mesh,\n",
    "                           zz,\n",
    "                           cmap='gnuplot2',\n",
    "                           norm=colors.LogNorm(),\n",
    "                           rstride=1,\n",
    "                           cstride=1,\n",
    "                           shade=False)\n",
    "\n",
    "    ax.set_zlabel(r\"$E(\\theta)$\")\n",
    "\n",
    "    fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "    ############################\n",
    "\n",
    "    if theta_star is not None:\n",
    "        ax.scatter(theta_star[0],\n",
    "                   theta_star[1],\n",
    "                   func(theta_star),\n",
    "                   c='red',\n",
    "                   alpha=1,\n",
    "                   label=r\"$\\theta^*$\")\n",
    "\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.set_xlabel(r\"$\\theta_0$\", fontsize=16)\n",
    "    ax.set_ylabel(r\"$\\theta_1$\", fontsize=16)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "937f649393f6d8f98d12d0e6e16ba8c2",
     "grade": false,
     "grade_id": "cell-be70105c106f3c0d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b73840777dd644d812e2f39ead068538",
     "grade": false,
     "grade_id": "cell-c85056646ced4537",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Today you will learn to solve regression problems using **parametric models** (the application of parametric models to classification problems will be the subject of another session): you will use a parametric function $f_{\\boldsymbol{\\theta}}: \\boldsymbol{x} \\mapsto y$ to infer the link existing between input vectors $\\boldsymbol{x} \\in \\mathbb{R}^p$ and output values $y \\in \\mathbb{R}$ in a *learning set* $\\mathcal{D} = \\{(\\boldsymbol{x^{(i)}}, y^{(i)})\\}_{1 \\leq i \\leq n}$ of $n$ examples.\n",
    "\n",
    "The *hypothesis space* $\\mathcal{H}$ of $f_{\\boldsymbol{\\theta}}$ is chosen *a priori*, so that the model fits reasonably well the data in $\\mathcal{D}$. For instance, $\\mathcal{H}$ can be the space of linear functions if the data seems to be distributed along a line in $\\mathcal{D}$. The space of polynomial functions of degree $d>1$ may be a good choice otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2d8fcdbea09dd6d12a6adab943d9b804",
     "grade": false,
     "grade_id": "cell-495715032500736b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The parameter $\\boldsymbol{\\theta}^* = \\begin{pmatrix} \\theta_0^* & \\dots & \\theta_p^* \\end{pmatrix}^T$ is then searched to obtain the best fit between $f_{\\boldsymbol{\\theta}}$ and $\\mathcal{D}$. This is an optimization problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "57c3a42f6dae1e2377364731debb07d8",
     "grade": false,
     "grade_id": "cell-d638b5451d2cc97c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For instance, assume you have chosen the space of linear functions to make a model that describes the data in $\\mathcal{D}$, and $p=1$ (one-dimensional regression).\n",
    "\n",
    "Your model is then $y = \\theta_0 + \\theta_1 x$ and the regression problem consists in finding the best parameters (strictly speaking, estimators of these parameters) $\\theta_0^\\star$ and $\\theta_1^\\star$ for it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a49474732a451cda53de06e6c41e5ee2",
     "grade": false,
     "grade_id": "cell-105796cda48284cd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Note**: there are some differences in notations with the lecture slides: parameters are noted $w$ (for \"weights\": machine learning community) in lectures but they are noted $\\theta$ (for parameters: statistics community) here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "97526d02d1d28fc667548df245707454",
     "grade": false,
     "grade_id": "cell-effda178ed28f9a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Linear regression: an analytic definition of the optimal parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6ea11488661142e8595889c4e5b9e37b",
     "grade": false,
     "grade_id": "cell-9e460f50efcfb03c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We have a *learning set* $\\mathcal{D} = \\{(\\boldsymbol{x^{(i)}}, y^{(i)})\\}_{1 \\leq i \\leq n}$.\n",
    "\n",
    "We assume:\n",
    "- Errors (difference between actual labels $y$ and predicted labels $\\hat{y} = f_{\\theta}(\\boldsymbol{x})$) are gaussian random values centered at 0: $y = f_{\\boldsymbol{\\theta}}(\\boldsymbol{x}) + \\epsilon$ with $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$.\n",
    "- Data is modeled with a linear function: $f_{\\boldsymbol{\\theta}}(\\boldsymbol{x}) = \\theta_0 + \\sum_{j=1}^p \\theta_j \\boldsymbol{x}_j = (1 \\; x)^T \\boldsymbol{\\theta}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ddac588d25e65304a0fd4d7b0379a43d",
     "grade": false,
     "grade_id": "cell-9f12cf6556b45692",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- Observations $\\boldsymbol{x} \\in \\mathbb{R}^p$ can be defined as $p$ random values $X_1, X_2, \\dots, X_p$\n",
    "- Labels $y$ are then realizations of a random value $Y$ such that:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "53d57619ca548009c952784563d6522c",
     "grade": false,
     "grade_id": "cell-9653f671cc4f867e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "$$Y \\sim \\mathcal{N}(\\underbrace{f(\\boldsymbol{x} | \\boldsymbol{\\theta})}_{\\mu}, \\sigma^2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e589c2b26f65e6112458a426de2d86d8",
     "grade": false,
     "grade_id": "cell-df29b0d7ce3ee807",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We want to find the estimator $\\boldsymbol{\\theta}^* = \\begin{pmatrix} \\theta_0^* & \\dots & \\theta_p^* \\end{pmatrix}^T$ that gives the best fit between $f_{\\boldsymbol{\\theta}}$ and $\\mathcal{D}$ (optimization problem).\n",
    "\n",
    "Finding the best $\\boldsymbol{\\theta}^*$ is a maximum likelihood problem : $\\boldsymbol{\\theta}^* \\leftarrow {\\arg\\!\\max}_{\\boldsymbol{\\theta}} \\mathbb{P}(\\mathcal{D}|\\boldsymbol{\\theta})$.\n",
    "Here, it is equivalent to apply the method of *least squares* or to minimize the Mean Square Error (MSE).\n",
    "Using matrix notation, we define the linear regression problem as:\n",
    "\n",
    "$$\\boldsymbol{\\theta}^* \\leftarrow {\\arg\\!\\min}_{\\boldsymbol{\\theta}} E(\\boldsymbol{\\theta}) \\quad \\text{with} \\quad E(\\boldsymbol{\\theta}) = (\\boldsymbol{y} - \\boldsymbol{X} \\boldsymbol{\\theta})^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "71c85b5168c21963e86829f7524c4570",
     "grade": false,
     "grade_id": "cell-61475c62d66cbf76",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "and\n",
    "\n",
    "$$\n",
    "\\boldsymbol{X} = \\begin{pmatrix} 1 & x_1^{(1)} & \\dots & x_p^{(1)} \\\\ \\vdots & \\vdots & \\dots & \\vdots \\\\ 1 & x_1^{(n)} & \\dots & x_p^{(n)} \\end{pmatrix}\n",
    "\\quad \\quad\n",
    "\\boldsymbol{y} = \\begin{pmatrix} y^{(1)} \\\\ \\vdots \\\\ y^{(n)} \\end{pmatrix}\n",
    "\\quad \\quad\n",
    "\\boldsymbol{\\theta} = \\begin{pmatrix} \\theta_0 \\\\ \\vdots \\\\ \\theta_p \\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "$E(\\boldsymbol{\\theta})$ is a quadratic form (convex function) thus it has a unique global minimum $\\boldsymbol{\\theta^*}$ where $\\nabla_{\\boldsymbol{\\theta^*}} E(\\boldsymbol{\\theta^*}) = \\boldsymbol{0}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e70117a5b9a61d94d8c04e9f341f716f",
     "grade": false,
     "grade_id": "cell-b82ff7d33e4f9d19",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 1\n",
    "\n",
    "On a sheet of paper:\n",
    "- Compute the analytic formulation of the gradient $\\nabla_{\\boldsymbol{\\theta}} E(\\boldsymbol{\\theta})$ of the Mean Square Error $E(\\boldsymbol{\\theta}) = (\\boldsymbol{y} - \\boldsymbol{X} \\boldsymbol{\\theta})^2$\n",
    "- Compute the analytic formulation of the optimal parameter $\\boldsymbol{\\theta^*}$\n",
    "\n",
    "You can first use $p=1$, but with a greater value of $p$, matrix notation (and calculus) will come in handy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2315b928abfeea518c03acfc35621eee",
     "grade": true,
     "grade_id": "cell-109713b1f8185947",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bcae707cf2acbbbcb76cce1cb9b04c5b",
     "grade": false,
     "grade_id": "cell-44cf7d2487981df4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "172d687f7f22e6c17b09b8f1091689a7",
     "grade": false,
     "grade_id": "cell-190d1365ff2067b0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "596f2d44269b5550fc87a3e6ef71c12c",
     "grade": false,
     "grade_id": "cell-e61f02986c51754a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e0ea21e53bdb648cdb5cd10e50ea655e",
     "grade": false,
     "grade_id": "cell-3f0edd2c6f447980",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Use the previous equations to compute **by hand** (i.e. on a sheet of paper) the optimal parameters $\\theta_0$ and $\\theta_1$ of the model $y = \\theta_0 + \\theta_1 x$ to best fit the following dataset (of four observations):\n",
    "\n",
    "$$\\mathcal{D} = \\left\\{\n",
    "\\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix},\n",
    "\\begin{pmatrix} 5 \\\\ 2 \\end{pmatrix},\n",
    "\\begin{pmatrix} 7 \\\\ 3 \\end{pmatrix},\n",
    "\\begin{pmatrix} 8 \\\\ 3 \\end{pmatrix}\n",
    "\\right\\}$$\n",
    "\n",
    "This will require [inverting a 2x2 matrix](https://www.chilimath.com/lessons/advanced-algebra/inverse-of-a-2x2-matrix/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0b62b1fe3581216666577d7fd916a6f6",
     "grade": false,
     "grade_id": "cell-dc059da0f663bf52",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X = [2, 5, 7, 8]\n",
    "y = [1, 2, 3, 3]\n",
    "\n",
    "plot_ex2(X, y)  # see in above how this is plotted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "58a287bdebdd319968ae15d772d24876",
     "grade": true,
     "grade_id": "cell-9b331f739a212645",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a35c57603b11a1b89ea15b488dcb783b",
     "grade": false,
     "grade_id": "cell-9ab9b404e1d089d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1e4be157f258552500dae33861615bf6",
     "grade": false,
     "grade_id": "cell-16b61b67d4d42e31",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Check graphically that the model you obtained fits the data well using the following cell (uncomment and complete the first two lines and uncomment the last one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d62256ccf58ec653209f828fb90516e3",
     "grade": false,
     "grade_id": "cell-504e60e2735f1d5f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# theta_0 = ...  # <- TO UNCOMMENT AND TO COMPLETE (intercept)\n",
    "# theta_1 = ...  # <- TO UNCOMMENT AND TO COMPLETE (slope)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "plot_ex2(X, y, theta_0, theta_1)  # see above how this is plotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c88884422a73aa4f201b76b649d891ac",
     "grade": true,
     "grade_id": "cell-e6276dfa3ea06270",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2c33a3a996700048f192c2255b4bd7a0",
     "grade": false,
     "grade_id": "cell-6b304de18ae86fa9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b966bb1afe8ae0314cbe3625b173fc79",
     "grade": false,
     "grade_id": "cell-b989380b0c14d3fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Plot the MSE $E(\\boldsymbol{\\theta})$ with the following cells.\n",
    "What is plotted? What is the input space and the output space?\n",
    "\n",
    "What can you say about these plots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8412764746d06f2dc86925ef82616d5",
     "grade": false,
     "grade_id": "cell-ffc9930c3f3c6455",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X = np.array([[1, 1, 1, 1], X]).T\n",
    "y = np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aa1d628436863adfb6fcc31c01c5f5a3",
     "grade": false,
     "grade_id": "cell-6a8128493dfd49c0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class MSE:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = np.copy(X)\n",
    "        self.y = np.copy(y)\n",
    "        \n",
    "    def __call__(self, theta):\n",
    "        return ((np.tile(self.y, theta.shape[1]) - np.dot(self.X, theta))**2).sum(axis=0)\n",
    "    \n",
    "mse = MSE(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "293c7a0f552c4308250104e8ae9adc27",
     "grade": false,
     "grade_id": "cell-7b5a60ff721eeab2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# see above how this is plotted\n",
    "plot_contour_2d_solution_space(mse,\n",
    "                               theta_min=np.array([-5, -1]),\n",
    "                               theta_max=np.array([5, 1]),\n",
    "                               theta_star=np.array([[theta_0], [theta_1]]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1ecd15110fa5a91bb23f79d7476582e",
     "grade": false,
     "grade_id": "cell-843ab44c0d1f56e3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# see above how this is plotted\n",
    "plot_2d_solution_space(mse,\n",
    "                       theta_min=np.array([-5, -1]),\n",
    "                       theta_max=np.array([5, 1]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3da918966d6c3cb3d39ba44531761f94",
     "grade": true,
     "grade_id": "cell-1bea2faf56cbc3f4",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "306052048a0c1ffd67cd540dcdf4decc",
     "grade": false,
     "grade_id": "cell-66e963a155d6cda0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Linear regression: an approximated solution using a *gradient descent* method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b23912abc45b29811d6bb818315f856c",
     "grade": false,
     "grade_id": "cell-05d4a04f2d442539",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "When $(X^TX)^{-1}$ cannot be easily computed (e.g. no analytical solution or $\\mathcal{D}$ contains a lot of examples or the dimension of the solution space $\\mathcal{X}$ is too large), an approximated solution can be computed using a *gradient descent method*.\n",
    "\n",
    "Also, we'll use *gradient descent* for other models than linear regression, so this will serve as an introduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "37c28819cd788c829b22cca567694ce3",
     "grade": false,
     "grade_id": "cell-5efce5b0664fc655",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "$\\nabla_{\\theta}E(\\hat{\\theta})$ gives the direction of the largest slope at the point $\\hat{\\theta}$.\n",
    "Thus, if we explore iteratively the parameter space by following the opposite direction of this gradient as described in the following definition, we should converge to the parameter $\\boldsymbol{\\theta}^\\star$ that minimizes the MSE, i.e. the parameter $\\theta^\\star$ such that $\\nabla_{\\theta^\\star}E({\\theta^\\star}) = 0$.\n",
    "\n",
    "Starting from a random point $\\boldsymbol{\\theta}$, the gradient descent method proposes a new point \n",
    "$\\boldsymbol{\\theta} \\leftarrow \\boldsymbol{\\theta} - \\eta \\nabla_{\\boldsymbol{\\theta}}E(\\boldsymbol{\\theta})$ at each iteration until a stopping criterion has been reached: e.g. $||\\nabla_{\\boldsymbol{\\theta}}E(\\boldsymbol{\\theta})||_2^2 > \\epsilon_{\\delta}$ with $\\epsilon_{\\delta}$ a chosen minimal length for the gradient to continue iterations.\n",
    "\n",
    "The *learning rate* $\\eta \\in \\mathbb{R}_+^*$ is a parameter to tweak for the considered problem.\n",
    "- If $\\eta$ is too large, the optimization may not converge toward 0.\n",
    "- If $\\eta$ is too small, the optimization may require a lot of iterations to converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9b0b8d84fd06378679e16baeda68bb37",
     "grade": false,
     "grade_id": "cell-e1e52ff12c64030a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2dd09aba7390ca4243c283a2601b49ca",
     "grade": false,
     "grade_id": "cell-b6cdd776c2d8dfcf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "52d12a6708b701ef873c61216f45a1f8",
     "grade": false,
     "grade_id": "cell-b9fe747665cacd18",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In our one-dimensional example of four points, calculate the expression of the gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "be1566373efd685f3f90e2ee0115f9c0",
     "grade": true,
     "grade_id": "cell-07604ff10943e768",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9b67fa20fa88dab850d4714999779a77",
     "grade": false,
     "grade_id": "cell-4db450174a002b3a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Implement a gradient descent method to solve exercise 2 with an approximated solution.\n",
    "Use the analytic formulation of $\\nabla_{\\boldsymbol{\\theta}}E(\\boldsymbol{\\theta})$ that has been computed in exercise 1.\n",
    "\n",
    "You can use a very basic stopping criterion: the number of iterations (e.g. 10000).\n",
    "You can start with $\\eta = 0.001$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d5faf338cf2811ca45c2e77ecf8b6110",
     "grade": false,
     "grade_id": "cell-afe0bcd08689954e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, eta=0.001, max_iteration=10000, \n",
    "                     theta=np.random.normal(loc=0, scale=10, size=[2, 1])):\n",
    "\n",
    "    # Perform useful matrix multiplication\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    grad_list = []      # Keep the gradient of all iterations\n",
    "    theta_list = []     # Keep the solution of all iterations\n",
    "\n",
    "    for i in range(max_iteration):\n",
    "        # Perform the gradient descent here\n",
    "        # grad = ...\n",
    "        # theta = ...\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "        grad_list.append([grad[0][0], grad[1][0]])      # Keep the gradient\n",
    "        theta_list.append([theta[0][0], theta[1][0]])   # Keep the solution\n",
    "\n",
    "    return grad_list, theta_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0045927ccc31702e5589649d7e5dc15a",
     "grade": true,
     "grade_id": "cell-c2d72b650eb9188e",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae90a9551dfbfe39b131539d8dd396f9",
     "grade": false,
     "grade_id": "cell-ea7a3ebf2e90c097",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "grad_list, theta_list = gradient_descent(X, y)\n",
    "\n",
    "dataframe_grad = pd.DataFrame(grad_list, columns=[\"grad1\", \"grad2\"])\n",
    "dataframe_theta = pd.DataFrame(theta_list, columns=[\"theta1\", \"theta2\"])\n",
    "\n",
    "dataframe_theta.tail()  # Display the last lines and observe convergence to what you found analytically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e9029b7f56952bdb7049ab3b8d19dc31",
     "grade": false,
     "grade_id": "cell-fa5f032a678d1191",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "575a3e7acae5b19973a50c9c5c06fa10",
     "grade": false,
     "grade_id": "cell-9e10cb411219f8f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Print or plot the value of $\\theta$ and $E(\\theta)$ obtained at each iteration.\n",
    "Check that $E(\\theta)$ converges to 0 and that $\\theta$ converges to the solution obtained in exercise 2.\n",
    "\n",
    "You can make use of `df_theta` as provided in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8bc8c2a7a438572849a466b977e88f68",
     "grade": false,
     "grade_id": "cell-95c473ba9cbf5611",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# theta_min = ...\n",
    "# theta_max = ...\n",
    "# theta_visited = ...  # numpy array of values of theta obtained through gradient descent (be careful about the expected shape)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# see above how this is plotted\n",
    "plot_contour_2d_solution_space(mse,\n",
    "                               theta_min=theta_min - 2.,\n",
    "                               theta_max=theta_max + 2.,\n",
    "                               theta_visited=theta_visited);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "14caca822d14eae0b90a05aa9dd977b8",
     "grade": false,
     "grade_id": "cell-9463cd2580ad5929",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "215be6c8ae938ef4bb483e6371306243",
     "grade": false,
     "grade_id": "cell-e7cb91b538975eee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Print or plot the norm of the gradient. You can make use of `dataframe_grad` provided earlier. How do you interpret it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4e2caaed4ecdc12e4afd114fdfd9a3e5",
     "grade": false,
     "grade_id": "cell-6c3628c367ef09e8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_gradient(df_gradient: pd.DataFrame):\n",
    "\n",
    "    # Put the norm of the gradient at each iteration in a column named \"norm\"\n",
    "    # df_gradient['norm'] = ...\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    ax = df_gradient.norm.plot(loglog=True, figsize=(16, 8))\n",
    "\n",
    "    ax.set_title(r\"Evolution of $||\\nabla_{\\theta} E(\\theta)||_2$\", fontsize=16)\n",
    "    ax.set_xlabel(\"Iteration number\", fontsize=16)\n",
    "    ax.set_ylabel(r\"Norm of $\\nabla_{\\theta} E(\\theta)$\", fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6459da151405bbc7a09af746b05694ec",
     "grade": true,
     "grade_id": "cell-99c2cc0144478abd",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plot_gradient(dataframe_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6c9fde05d0e63c7c120b90fa07e5e50b",
     "grade": false,
     "grade_id": "cell-0c9ff61378716aa0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "448cf079f2f6cfb9f95030f951723959",
     "grade": false,
     "grade_id": "cell-3d83db1d4a842a37",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Restart the optimization using a different *learning rate* $\\eta$. What do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6d69ff1b864a86b48011559cdfd3dfd9",
     "grade": true,
     "grade_id": "cell-b2d33e0b58aa0a50",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7affca731bb791856c9f6eabc77e1d87",
     "grade": true,
     "grade_id": "cell-bbf38ec3627452f2",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Try with different values of eta (and optionally theta) IN SEPARATE CODE CELLS\n",
    "def display_theta_visited_norm(eta=0.000001, theta=np.array([[7],[2]]), max_iteration=10000):\n",
    "    # grad_list, theta_list = gradient_descent(...)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # Use the same procedure as previously:\n",
    "    df_grad = pd.DataFrame(grad_list, columns=[\"grad1\", \"grad2\"])\n",
    "    df_theta = pd.DataFrame(theta_list, columns=[\"theta1\", \"theta2\"])\n",
    "    # theta_min = ...\n",
    "    # theta_max = ...\n",
    "    # theta_visited = ...\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # see above how this is plotted\n",
    "    plot_contour_2d_solution_space(mse,\n",
    "                                   theta_min=theta_min - 2.,\n",
    "                                   theta_max=theta_max + 2.,\n",
    "                                   theta_visited=theta_visited);\n",
    "\n",
    "    # Computing the norm\n",
    "    plot_gradient(df_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d676f26d792f7833eebf929f7266ae1b",
     "grade": true,
     "grade_id": "cell-137404677de06a04",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# display_theta_visited_norm(...)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "116d9d30c495d4a9c4e4aecbf6628bc0",
     "grade": true,
     "grade_id": "cell-f0756f5088f332b9",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# display_theta_visited_norm(...)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d5791c09ba6423f5108be7af353fbda",
     "grade": true,
     "grade_id": "cell-f36a940ff6361975",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# display_theta_visited_norm(...)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "11d22a47c001cf1503286332a9f2bb36",
     "grade": true,
     "grade_id": "cell-f1342ed3d5337e67",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4655427807a7168080483689671039ae",
     "grade": true,
     "grade_id": "cell-24168347033f89a0",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a1a396a08bb793c451f8fd06ef8ef73f",
     "grade": false,
     "grade_id": "cell-a7594039d1965484",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Linear regression with Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3acee9ab14cb933a8b92c68b96894d2b",
     "grade": false,
     "grade_id": "cell-80cf226d39c1feeb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's play with the Scikit Learn implementation of linear regression.\n",
    "The official documentation is there: https://scikit-learn.org/stable/modules/linear_model.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "65892b9660715da48adcdf7f23f5d2c5",
     "grade": false,
     "grade_id": "cell-b160f4cf12cf6b6b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Use the `gen_1d_linear_regression_samples()` function (defined above) to generate a dataset and `plot_1d_regression_samples()` to plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27b78153f5a5c2f091396b76b23d1f7a",
     "grade": false,
     "grade_id": "cell-0bda972706db0f96",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = gen_1d_linear_regression_samples()\n",
    "\n",
    "plot_1d_regression_samples(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "43818da8ae6818cf5bc9c139a5eb4e5e",
     "grade": false,
     "grade_id": "cell-932ebeb64bb5a2b7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Once the dataset is ready, let's make the regressor and train it with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3a818931c5de409cb3ceb9b5c777629b",
     "grade": false,
     "grade_id": "cell-f09fbaa43b826133",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "linear_model = sklearn.linear_model.LinearRegression()\n",
    "\n",
    "linear_model.fit(df[['x']], df[['y']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3c894ac1abd8daf1075d9da7d865c5d7",
     "grade": false,
     "grade_id": "cell-39264ad22cf7a195",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The following cell plots the learned model (the red dashed line) and the dataset $\\mathcal{D}$ (blue points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2017b717bde735a23620c21d0eae6f6d",
     "grade": false,
     "grade_id": "cell-edc6674474d43365",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plot_1d_regression_samples(df, model=linear_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "477ee209454a9d608db067ab6f91a9aa",
     "grade": false,
     "grade_id": "cell-b7fbd3a64e51ee80",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "54d622ae9f519485318c1ee2e1823edd",
     "grade": false,
     "grade_id": "cell-1770c0dbfa328904",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fb64e3ecb31a2949f87cabc74aed6692",
     "grade": false,
     "grade_id": "cell-0c8e89bc5e840013",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "What are the optimal parameters $\\theta_1$ (intercept) and $\\theta_2$ obtained? Put them in `intercept` and `slope`.\n",
    "(Note: there are attributes to the `LinearRegression` class which provide them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "548fb518c41e5a99a6f815e472a00a02",
     "grade": false,
     "grade_id": "cell-e2aa27ffe5b33569",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# intercept = ...  # TO UNCOMMENT\n",
    "# slope = ...  # TO UNCOMMENT\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ffaab9f7c3d0d5b9023d03c6feebc14c",
     "grade": true,
     "grade_id": "cell-a310e1610f39308d",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8376a041786b81cfe60ddfd904f4cc22",
     "grade": false,
     "grade_id": "cell-7f425446c98adcae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "91b99c5cd13e62fd138aa04512fdfbae",
     "grade": false,
     "grade_id": "cell-3af6a3541617d567",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Write the mathematical definition of the generated data (see above) and your model.\n",
    "\n",
    "Implement both as a function of X and plot it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8b21e47ad08d97befa5b3156c7316a2e",
     "grade": true,
     "grade_id": "cell-2bd7bc7d944edb1b",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "35c5e09dfd4872abe7cf3bcd5e779591",
     "grade": true,
     "grade_id": "cell-5eb0efb6698f74f5",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def f(X):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def f_hat(X):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "ax = df.plot.scatter(x='x', y='y', figsize=(16, 6))\n",
    "\n",
    "X = np.array([-10, 10])\n",
    "ax.plot(X, f(X))\n",
    "ax.plot(X, f_hat(X));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0b92952d375f5bc4d985d63640757803",
     "grade": false,
     "grade_id": "cell-a7c01692a2600a0c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3068d952923b06f88e6bb0b69eba5864",
     "grade": false,
     "grade_id": "cell-61e1f78258673ea2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Use the `model.predict()` function to guess the class of the following points in a *vectorized* way (i.e. applying the `predict` method on an array, and returning and an array); put the result in `linear_predictions`:\n",
    "\n",
    "$$x_{p1} = -2, \\quad x_{p2} = 2, \\quad x_{p3} = 6$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5419d9947e52f5f9d5e9532c039d9fc7",
     "grade": false,
     "grade_id": "cell-3b0196a9e393373d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# predictions = ...  # TO UNCOMMENT\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6defb98e773cac6fedbfdcf045ccb1c9",
     "grade": true,
     "grade_id": "cell-b08dd318b2a33497",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e315b43b89e7b504d7eb8ffe7f64b03c",
     "grade": false,
     "grade_id": "cell-ea69acf8a4eeafae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Polynomial regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6c6b2f359ab76b7f67397163f2fd9851",
     "grade": false,
     "grade_id": "cell-9af4759b11aae65e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "It is a common practice to use linear models trained on nonlinear transformations of the input data in machine learning. This approach maintains the generally fast performance of linear methods, while allowing them to fit a much wider range of data.\n",
    "\n",
    "For instance, a linear model can be extended by making polynomial features from the coefficients. Linear model in exercises 1 and 2 looks like this (one-dimensional data):\n",
    "\n",
    "$$f_{\\theta}(x) = \\theta_0 + \\theta_1 x$$\n",
    "\n",
    "If we want to fit a quadratic curve to the data instead of a line, we can combine the features in second-order polynomials, so that the model looks like this:\n",
    "\n",
    "$$f_{\\theta}(x) = \\theta_0 + \\theta_1 x + \\theta_2 x^2$$\n",
    "\n",
    "This is still a linear model: to illustrate this, we can create a new variable\n",
    "\n",
    "$$z = [x, x^2]$$\n",
    "\n",
    "With this re-labeling of the data, our problem can be written\n",
    "\n",
    "$$f_{\\theta}(x) = \\theta_0 + \\theta_1 z_1 + \\theta_2 z_2$$\n",
    "\n",
    "The resulting polynomial regression is in the same class of linear models we'd considered above (i.e. the model is linear in $\\theta$) and can be solved by the same techniques. Thus the linear model has the flexibility to fit a much broader range of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "99e1d0a1f7658bf7acae763e31380328",
     "grade": false,
     "grade_id": "cell-da455a84c874bc2c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cf84ed078b65a089bbaa54517ba3d90d",
     "grade": false,
     "grade_id": "cell-c5abc9da3393b15e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "06be6d5aaac942721029b58e5d3c9a88",
     "grade": false,
     "grade_id": "cell-b2b7efb8efee00d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Use the previous equations to compute **by hand** (i.e. on a sheet of paper) the optimal parameters $\\theta_1$ and $\\theta_2$ of the model $y = \\theta_1 x + \\theta_1 x^2$ to best fit the following dataset (of four examples):\n",
    "\n",
    "$$\\mathcal{D} = \\left\\{\n",
    "\\begin{pmatrix} 1 \\\\ 1.8 \\end{pmatrix},\n",
    "\\begin{pmatrix} 2 \\\\ 2.7 \\end{pmatrix},\n",
    "\\begin{pmatrix} 3 \\\\ 3.4 \\end{pmatrix},\n",
    "\\begin{pmatrix} 4 \\\\ 3.8 \\end{pmatrix},\n",
    "\\begin{pmatrix} 5 \\\\ 3.9 \\end{pmatrix}\n",
    "\\right\\}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "415b2cb2b6c0fff5e3ba60b803772b19",
     "grade": true,
     "grade_id": "cell-9a82b72415381982",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "246a34a997d7a13bdf6f7ff8c371acdf",
     "grade": false,
     "grade_id": "cell-67f540250ea72831",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You can (optionnally) check your results using `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b79121946de84536f0dadc9f4d6080c",
     "grade": false,
     "grade_id": "cell-2c1a044c8c32910c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ad78bd258da907040c810480cc3ef67d",
     "grade": false,
     "grade_id": "cell-9a0d8e56ddad1916",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's plot these points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9adba7f5c403a3f5a363d9cd5f7e3d13",
     "grade": false,
     "grade_id": "cell-88fcd160737086f6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X = [1, 2, 3, 4, 5]\n",
    "y = [1.8, 2.7, 3.4, 3.8, 3.9]\n",
    "\n",
    "plot_ex4(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7d32efa1d94823864b71d82677a14eaa",
     "grade": false,
     "grade_id": "cell-5dc7678377669961",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1a4b97feb1a79cab8969b92f2714067d",
     "grade": false,
     "grade_id": "cell-c8925b27745ffbe3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Check graphically that the model you obtained fits the data well using the following cell (complete the first two lines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "032063f3e9d776af67d2f04719c2d49f",
     "grade": false,
     "grade_id": "cell-743068a487e386fc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X = [1, 2, 3, 4, 5]\n",
    "y = [1.8, 2.7, 3.4, 3.8, 3.9]\n",
    "\n",
    "# theta_1 = ...  # <- TO UNCOMMENT\n",
    "# theta_2 = ...  # <- TO UNCOMMENT\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "plot_ex4(X, y, theta_1, theta_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fca3967c03c86d90f38fc46ae17523b6",
     "grade": true,
     "grade_id": "cell-68076cc461b7aa4c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1dd05aa7b30f9ae6a5b8579b0f7e36fa",
     "grade": false,
     "grade_id": "cell-0fe2836d24ce791b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Polynomial regression with Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "406336b103c4a1c0f4acb7e550d1e3d8",
     "grade": false,
     "grade_id": "cell-273e499ff0c0af37",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's play with the Scikit Learn implementation of polynomial regression.\n",
    "The official documentation is there: https://scikit-learn.org/stable/modules/linear_model.html#polynomial-regression-extending-linear-models-with-basis-functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "39dba862ec58bc34eabc5640eec2f138",
     "grade": false,
     "grade_id": "cell-b18c3e59c8b19397",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "First we generate the dataset, plot it, instantiate a regressor and train it with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gen_1d_polynomial_regression_samples(n_samples=100)\n",
    "\n",
    "plot_1d_regression_samples(df)\n",
    "\n",
    "polynomial_features = sklearn.preprocessing.PolynomialFeatures(degree=3)  # In Q. 4, try with degree = 1, 4 and 15\n",
    "\n",
    "def learn_poly_model(poly_features: sklearn.preprocessing.PolynomialFeatures):\n",
    "    linear_regression = sklearn.linear_model.LinearRegression(fit_intercept=False)\n",
    "\n",
    "    model = sklearn.pipeline.Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "                                       (\"linear_regression\", linear_regression)])\n",
    "\n",
    "    model.fit(df[['x']], df[['y']])\n",
    "    return linear_regression, model\n",
    "\n",
    "linear_regression, model = learn_poly_model(polynomial_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6582bf6bc6fc1e87da047171aa2ca668",
     "grade": false,
     "grade_id": "cell-60b5a0fd85c1b670",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In `sklearn.preprocessing.PolynomialFeatures()`, `degree` is the degree of the polynomal function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "37b3f8075594e8a10ab7826c6f20d78b",
     "grade": false,
     "grade_id": "cell-1ec55b18f7da9027",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The following cell plots the learned model (the red dashed line) and the dataset $\\mathcal{D}$ (blue points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5acdd9b522fc0d044c67920efd15d2be",
     "grade": false,
     "grade_id": "cell-a82fa33137de7f52",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plot_1d_regression_samples(df, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f999d230165ef0cbb5e8e03fb13bf15e",
     "grade": false,
     "grade_id": "cell-ca25c567cdcf63dc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "08b399531a3b962d669e4dba0dec2e62",
     "grade": false,
     "grade_id": "cell-df3505a40854ace0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0f3d526d1f214b9ea133024cce1b6396",
     "grade": false,
     "grade_id": "cell-41f631b52fc8952d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "What are the optimal parameters $\\theta_0, \\theta_1, \\theta_2, \\theta_3$ obtained? Check the attributes of `linear_regression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf210ce95ca69971e721ab05a746deeb",
     "grade": false,
     "grade_id": "cell-b91f19a4815fe3af",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# theta_0 = ...\n",
    "# theta_1 = ...\n",
    "# theta_2 = ...\n",
    "# theta_3 = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ffc5b0e6ddf65349bebe05faa3f1dc25",
     "grade": true,
     "grade_id": "cell-bb52e963cc4ce55c",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ae94fcdfdf7e3caa9f0f00eae0ee777f",
     "grade": false,
     "grade_id": "cell-abaee08269799d13",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2f37a563c1c7fabf8bc621f574272074",
     "grade": false,
     "grade_id": "cell-0fa045dedd3f7af1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Write the mathematical definition of the generated data (see above) and your model. Plot the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7c20d1bad9e3a9d09eac3202bf0d7c1b",
     "grade": true,
     "grade_id": "cell-c98b8e5c3afe817b",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ffaa00889c177e198593d4c0dadf9fd9",
     "grade": false,
     "grade_id": "cell-9b7da27fe4c56be2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0., 10., 50)\n",
    "\n",
    "# y_hat = ...  # <- TO UNCOMMENT: this is sklearn's prediction\n",
    "# y = ...  # <- TO UNCOMMENT: this is the equation you found by looking above\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "ax = df.plot.scatter(x='x', y='y', figsize=(14, 6))\n",
    "\n",
    "df_model = pd.DataFrame(np.array([x, y, y_pred]).T, columns=['x', 'y', 'y_pred'])\n",
    "\n",
    "df_model.plot(x='x', y='y', style=':r', label='actual y', ax=ax)\n",
    "df_model.plot(x='x', y='y_pred', label='y predicted', ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cc8c29d9d09880d516b0bb130a355cf9",
     "grade": false,
     "grade_id": "cell-34a1d1428212f1d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "50c63b6e29d9072d0c08b3d96f60c383",
     "grade": false,
     "grade_id": "cell-92778884a8237af7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Use the `model.predict()` function to infer the `y` value of the following points:\n",
    "\n",
    "$$x_{p1} = 1, \\quad x_{p2} = 2, \\quad x_{p3} = 6$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a5eb339248aa70f8f59b31bb479f5572",
     "grade": false,
     "grade_id": "cell-5316fdd4671338b9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# predictions = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d87421d5fa9bca323050c4cc8b00d1c5",
     "grade": true,
     "grade_id": "cell-9139d7805b7a5da9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e3d719f7ee4cc318048bfadc85c1a938",
     "grade": false,
     "grade_id": "cell-6dfe74e982d3c4a2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1f009e79311993a6d7fdc7848feb9ca1",
     "grade": false,
     "grade_id": "cell-177f5049053e9bdb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In `sklearn.preprocessing.PolynomialFeatures()`, change the value of `degree` and describe what happen on the plot (use e.g. 1 and 15 - possibly with fewer observations).\n",
    "What is the name of the observed phenomenons?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "981054a726c3db34dc958d9f5f682302",
     "grade": true,
     "grade_id": "cell-4159c28a527f8e14",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "afc4dfaa39f28108069602d5a9b6b349",
     "grade": true,
     "grade_id": "cell-803b95bd0c968001",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# polynomial_features = ...  # TO UNCOMMENT, use e.g. degree 1\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "linear_regression, model = learn_poly_model(polynomial_features)\n",
    "\n",
    "plot_1d_regression_samples(df, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a3aaf892a5919f8dbf4ba6b13d4c51e3",
     "grade": true,
     "grade_id": "cell-e840b6c03f7592a6",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "638e08173a89663362e1de55032d740e",
     "grade": true,
     "grade_id": "cell-32f3059837b84e50",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = gen_1d_polynomial_regression_samples(n_samples=10)\n",
    "\n",
    "# polynomial_features = ...  # TO UNCOMMENT, use e.g. degree 15\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "linear_regression, model = learn_poly_model(polynomial_features)\n",
    "\n",
    "plot_1d_regression_samples(df, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e3186d70e3d0db76bfca5cb82c39741b",
     "grade": false,
     "grade_id": "cell-4291e83e9d6f58ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## CO2 Emission Forecast (bonus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7e3422fe3ddc5916ce12105f4180b185",
     "grade": false,
     "grade_id": "cell-e2a7a58758db5540",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this exercise, you will forecast 5 years of future CO2 emission from power generation using natural gas.\n",
    "\n",
    "This exercise use a dataset taken from https://www.kaggle.com/berhag/co2-emission-forecast-with-python-seasonal-arima.\n",
    "\n",
    "This public dataset contain monthly carbon dioxide emissions from electricity generation. The dataset includes CO2 emissions starting January 1973 to July 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b1be634f8613f10d0a81e1d30994cdd9",
     "grade": false,
     "grade_id": "cell-f4ec940d7fe3fb22",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "URL = \"https://raw.githubusercontent.com/adimajo/CSE204-2021/master/data/natural_gas_co2_emissions_for_electric_power_sector.csv\"\n",
    "\n",
    "df = pd.read_csv(URL,\n",
    "                 parse_dates=[0]) #, index_col=0) #, squeeze=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4d406296869f74c7afb2614c36bd8b3",
     "grade": false,
     "grade_id": "cell-e569fa4bb7e02b65",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df.plot(x='date', y='co2_emissions', figsize=(15,10), title='Natural Gas Electric Power Sector CO2 Emissions');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e4ce4345d31b108c4f0eb26fc5975a66",
     "grade": false,
     "grade_id": "cell-2524cba1576919b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 7 (bonus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8e0e4f8b54f5f08c68c39d8c54e3c32e",
     "grade": false,
     "grade_id": "cell-0f3199ca4199ef09",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Implement a model to make predictions on this dataset.\n",
    "Use polynomial basis functions plus two sinusoids to handle the seasonality of this time series: $\\sin(\\frac{2 \\pi}{12} x)$ and $\\cos\\left(\\frac{2 \\pi}{12} x \\right)$. This signal contains a periodic component of 12 time steps (where one time step equals to one month).\n",
    "\n",
    "We use both $\\sin$ and $\\cos$ to avoid unaligned phases with the time series. Alternatively, we could use only $\\sin\\left(\\frac{2 \\pi}{12} (x + \\phi)\\right)$ or $\\cos\\left(\\frac{2 \\pi}{12} (x + \\phi)\\right)$ as long as $\\phi$ is properly set: $\\phi = \\pi / 2$ in the first case and $\\phi = 0$ in the second one.\n",
    "\n",
    "What are the limitations of this model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "10b24f043ea774648ee168addf412f36",
     "grade": true,
     "grade_id": "cell-106b84e0a7ac2494",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "620d048a2497dccbb60bc70b525035bd",
     "grade": true,
     "grade_id": "cell-62bb51115ccdd8a9",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0560b9984e05b1f0efeae3ff67e754f4",
     "grade": true,
     "grade_id": "cell-4e87cf97568b97c9",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d2091a4f9b0023dadb8b85d5e8f03448",
     "grade": true,
     "grade_id": "cell-ee0f57f8b318cc78",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6a7f42b4b82b787e509ce179ea993cd9",
     "grade": true,
     "grade_id": "cell-0006ec1dea5f87f9",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f824d498390cf5860e0a0f9bad21a17f",
     "grade": true,
     "grade_id": "cell-a8de0d861f176e56",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8ade3c73df9eb95ff3ade78933d5226c",
     "grade": true,
     "grade_id": "cell-6fd0e0c8b3f6fd4b",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fb23de01522e550be5e25ea49c3bcda8",
     "grade": true,
     "grade_id": "cell-b97960e011f5f991",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ca41f0ee3375817fb381bc44fbf0a919",
     "grade": true,
     "grade_id": "cell-e4df8a22b942b669",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4e58d52b15bcd2da7d9c46d7e9521742",
     "grade": true,
     "grade_id": "cell-d94f61844dd909e3",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2dfa79bfb6861e9abf2ad06d7b10be74",
     "grade": true,
     "grade_id": "cell-46cd582ab2c5f162",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2aa8c965f563bd6372d56afe18ff24ce",
     "grade": true,
     "grade_id": "cell-bbba65658884f3a7",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSE204",
   "language": "python",
   "name": "cse204"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
